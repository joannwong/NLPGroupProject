{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Some references**\n",
    "\n",
    "https://www.kaggle.com/code/minhsienweng/train-infer-pii-detection-deberta-v3\n",
    "\n",
    "(no training) https://www.kaggle.com/code/manavtrivedi/0-967-nlp-sakura/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\nlp\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import datasets\n",
    "import tqdm\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, DataCollatorForTokenClassification, Trainer, TrainingArguments\n",
    "from scipy.special import softmax\n",
    "from sklearn.model_selection import train_test_split\n",
    "from spacy.lang.en import English\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from ignite.metrics import Fbeta\n",
    "from functools import partial\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.metrics import recall_score, precision_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from torch.nn.functional import softmax\n",
    "from peft import get_peft_model, LoraConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 labels, with the following labels:\n",
      " ['I-URL_PERSONAL', 'B-STREET_ADDRESS', 'B-PHONE_NUM', 'B-NAME_STUDENT', 'O', 'I-NAME_STUDENT', 'B-USERNAME', 'I-STREET_ADDRESS', 'I-PHONE_NUM', 'B-URL_PERSONAL', 'B-EMAIL', 'I-ID_NUM', 'B-ID_NUM']\n"
     ]
    }
   ],
   "source": [
    "#Finding out the number of labels\n",
    "data = json.load(open('data/train.json'))\n",
    "\n",
    "\n",
    "all_labels = set()\n",
    "\n",
    "for d in data:\n",
    "    all_labels = all_labels.union(set(d['labels']))\n",
    "\n",
    "print(f\"{len(list(all_labels))} labels, with the following labels:\\n {list(all_labels)}\")\n",
    "del data\n",
    "\n",
    "label2id = {label:index for index,label in enumerate(all_labels)}\n",
    "id2label = {index:label for index,label in enumerate(all_labels)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'I-URL_PERSONAL', 'B-STREET_ADDRESS', 'B-PHONE_NUM', 'B-NAME_STUDENT', 'O', 'I-NAME_STUDENT', 'B-USERNAME', 'I-STREET_ADDRESS', 'I-PHONE_NUM', 'B-URL_PERSONAL', 'B-EMAIL', 'I-ID_NUM', 'B-ID_NUM'}\n"
     ]
    }
   ],
   "source": [
    "print(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change to one-hot vector\n",
    "def oh_encoder(labels):  #label: array of output for each sentence\n",
    "\n",
    "    # unique_labels = ['O', 'B-NAME_STUDENT','I-NAME_STUDENT','B-PHONE_NUM', 'I-PHONE_NUM','B-ID_NUM', 'I-ID_NUM',  'B-URL_PERSONAL','I-URL_PERSONAL',\n",
    "    #                   'B-STREET_ADDRESS', 'I-STREET_ADDRESS',  'B-EMAIL', 'B-USERNAME']\n",
    "    \n",
    "    \n",
    "    unique_labels = ['O', 'B-NAME_STUDENT','I-NAME_STUDENT','B-URL_PERSONAL', 'B-ID_NUM','I-ID_NUM','B-EMAIL','I-STREET_ADDRESS',\n",
    "                     'I-PHONE_NUM', 'B-USERNAME', 'B-PHONE_NUM','B-STREET_ADDRESS', 'I-URL_PERSONAL']\n",
    "    \n",
    "    labels_oh = []\n",
    "    for label in labels:    #label: str\n",
    "        label_oh = [float(0)]*len(unique_labels)\n",
    "        for k in range(len(unique_labels)):\n",
    "            if unique_labels[k] == label:\n",
    "                label_oh[k] = 1\n",
    "                #labels_oh.append(torch.tensor(label_oh, requires_grad=True))\n",
    "                labels_oh.append(label_oh)\n",
    "                break\n",
    "                \n",
    "\n",
    "    #return torch.tensor(labels_oh, requires_grad=True)\n",
    "    return torch.tensor(labels_oh, requires_grad=True, dtype=float)    #list of one-hot labels as tensors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(example, tokenizer):\n",
    "    import numpy as np\n",
    "    # Preprocess the tokens and labels by adding trailing whitespace and labels\n",
    "    tokens = []\n",
    "    labels = []\n",
    "    for token, label, t_ws in zip(example[\"tokens\"], \n",
    "                                  example[\"labels\"],\n",
    "                                  example[\"trailing_whitespace\"]):\n",
    "        tokens.append(token)\n",
    "        labels.extend([label] * len(token))\n",
    "        # Added trailing whitespace and label if true and \n",
    "        if t_ws:\n",
    "            tokens.append(\" \")\n",
    "            # labels.append(oh_encoder(\"O\"))\n",
    "            labels.append(\"O\")\n",
    "    \n",
    "    text = \"\".join(tokens)\n",
    "    # print(f\"len(text)={len(text)}, len(tokens)={len(tokens)}\")\n",
    "    # tokenization without truncation\n",
    "    tokenized = tokenizer(text, return_offsets_mapping=True,\n",
    "                          truncation=False)\n",
    "    #labels = np.array(labels)\n",
    "    # Labels\n",
    "    token_labels = []\n",
    "    for start_idx, end_idx in tokenized.offset_mapping:\n",
    "        # Added 'O' \n",
    "        if start_idx == 0 and end_idx == 0:\n",
    "            #token_labels.append(label2id[\"O\"]) \n",
    "            #token_labels.append(oh_encoder(\"O\"))\n",
    "            token_labels.append(\"O\")\n",
    "        else:\n",
    "            # case when the text starts with whitespace\n",
    "            if text[start_idx].isspace():\n",
    "                start_idx += 1\n",
    "            # Convert label to id (int)\n",
    "            #label_id = label2id[labels[start_idx]]\n",
    "            label_id = labels[start_idx]\n",
    "            #token_labels.append(oh_encoder(label_id))\n",
    "            token_labels.append(label_id)\n",
    "\n",
    "    return {**tokenized, \"labels\": token_labels, \"length\": len(tokenized.input_ids)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(outputs, labels, unique_labels = ['O', 'B-NAME_STUDENT','I-NAME_STUDENT','B-URL_PERSONAL', \n",
    "                                                          'B-ID_NUM','I-ID_NUM','B-EMAIL','I-STREET_ADDRESS',\n",
    "                                                          'I-PHONE_NUM', 'B-USERNAME', 'B-PHONE_NUM','B-STREET_ADDRESS', 'I-URL_PERSONAL']):    \n",
    "    try:\n",
    "        #print(\"Compute metrics\")\n",
    "        predictions = torch.argmax(softmax(outputs, dim=2), dim=2)\n",
    "        # Include prediction Remove ignored index (special tokens)\n",
    "        true_preds = []\n",
    "        true_labels = []\n",
    "        for pred, label in zip(predictions, labels):\n",
    "            true_preds.append([unique_labels[p] for p, l in zip(pred, label) if l[0] != -100])\n",
    "            true_labels.append([unique_labels[torch.argmax(l)] for p, l in zip(pred, label) if l[0] != -100])\n",
    "        \n",
    "        mlb = MultiLabelBinarizer(classes=unique_labels)\n",
    "        true_preds_bin = mlb.fit_transform(true_preds)\n",
    "        true_labels_bin = mlb.transform(true_labels)\n",
    "        # Compute recall, precision and f5 score\n",
    "        recall = recall_score(true_labels_bin, true_preds_bin, average='samples')\n",
    "        precision = precision_score(true_labels_bin, true_preds_bin, average='samples')\n",
    "        # Use modified f5 score to measure the performance\n",
    "        f5_score = (1 + 5*5) * (recall * precision / (5*5*precision + recall))\n",
    "        result = {'f5': f5_score,  \n",
    "                  'recall': recall,\n",
    "                  'precision': precision}\n",
    "        # print(f\"result = {result}\")\n",
    "        return result\n",
    "    except Exception as e: \n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model: DeBERTa (Custom)\n",
    "\n",
    "Using a pretrained DeBERTa, we will build a classifier head on top of it to predict the class at token level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Classifier(nn.Module):\n",
    "#     def __init__(self, input_dim, hidden_dim, output_dim = 13):\n",
    "#         super(Classifier, self).__init__()\n",
    "\n",
    "#         self.dropout_prob = 0.3\n",
    "#         self.final_activation = nn.Softmax(dim = -1)\n",
    "\n",
    "#         self.linear = nn.Sequential(\n",
    "#             nn.ReLU(nn.Linear(input_dim, hidden_dim)),\n",
    "            \n",
    "#             nn.Dropout(self.dropout_prob),\n",
    "#             nn.ReLU(nn.Linear(hidden_dim, hidden_dim*2)),\n",
    "\n",
    "#             nn.Dropout(self.dropout_prob),\n",
    "#             nn.ReLU(nn.Linear(hidden_dim*2, hidden_dim)),\n",
    "\n",
    "#             nn.Linear(hidden_dim, output_dim)\n",
    "#         )\n",
    "       \n",
    "\n",
    "#     def forward(self, x):\n",
    "#         logit = self.linear(x)\n",
    "#         return self.final_activation(logit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Classifier(nn.Module):\n",
    "#     def __init__(self, input_dim, hidden_dim, output_dim = 13):\n",
    "#         super(Classifier, self).__init__()\n",
    "\n",
    "#         self.dropout_prob = 0.3\n",
    "#         self.final_activation = nn.Softmax(dim = -1)\n",
    "\n",
    "#         self.dropout = nn.Dropout(self.dropout_prob)\n",
    "#         self.linear1 = nn.ReLU(nn.Linear(input_dim,hidden_dim))\n",
    "#         self.linear2 = nn.ReLU(nn.Linear(hidden_dim, hidden_dim*2))                            \n",
    "#         self.linear3 = nn.ReLU(nn.Linear(hidden_dim*2, hidden_dim))\n",
    "#         self.output = nn.Linear(hidden_dim,output_dim)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         print('now start linear1')\n",
    "#         print(x.size())\n",
    "#         x = self.linear1(x)\n",
    "\n",
    "#         print('now start linear2')\n",
    "#         print(x.size())\n",
    "#         x = self.linear2(self.dropout(x))\n",
    "\n",
    "#         print('now start linear3')\n",
    "#         print(x.size())\n",
    "#         x = self.linear3(self.dropout(x))\n",
    "\n",
    "#         print('now start output')\n",
    "#         print(x.size())\n",
    "#         logit= self.output(x)\n",
    "        \n",
    "#         print('now start activation')\n",
    "#         output =  self.final_activation(logit)\n",
    "        \n",
    "#         return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Deberta_Classif(Classifier):\n",
    "#     def __init__(self, model_name, classif_input, classif_hidden, classif_output = 13, finetune = False):\n",
    "#         super(Deberta_Classif, self).__init__(classif_input, classif_input)\n",
    "#         self.ft = finetune\n",
    "\n",
    "#         self.extractor = AutoModelForTokenClassification.from_pretrained(model_name).base_model\n",
    "\n",
    "#         if not finetune:\n",
    "#             for param in self.extractor.parameters():\n",
    "#                 param.requires_grad = False\n",
    "\n",
    "#         self.extractor_num_param =  sum(p.numel() for p in self.extractor.parameters())\n",
    "#         self.extractor_num_param_grad = sum(p.numel() for p in self.extractor.parameters() if p.requires_grad)\n",
    "#         self.extractor_name = \"DeBERTa\"\n",
    "                \n",
    "\n",
    "#         self.classifier = Classifier(input_dim=classif_input, hidden_dim=classif_hidden ,output_dim=classif_output)\n",
    "#         self.classifier_num_param = sum(p.numel() for p in self.classifier.parameters() if p.requires_grad)\n",
    "\n",
    "        \n",
    "#     def count_param(self):\n",
    "        \n",
    "#         if self.ft:\n",
    "#             type = 'finetuned'\n",
    "#             num_param = self.extractor_num_param_grad + self.classifier_num_param\n",
    "#         else:\n",
    "#             type = 'non-finetuned'\n",
    "#             num_param = self.extractor_num_param + self.classifier_num_param\n",
    "\n",
    "#         print(f\"Number of parameters in {type} {self.extractor_name} model is {num_param:,}\")\n",
    "    \n",
    "    \n",
    "#     def forward(self, input_ids, attention_mask):\n",
    "#         x = self.extractor(input_ids, attention_mask).last_hidden_state\n",
    "#         x = self.classifier(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForTokenClassification were not initialized from the model checkpoint at MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([13]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([13, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's trainable parameters:  9,997\n",
      "Model's total parameters:  191,509,261\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_name = \"MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli\"\n",
    "# model_name = \"microsoft/deberta-v3-small\"\n",
    "#model = Deberta_Classif(model_name, classif_input = 768, classif_hidden = 100, classif_output = 13, finetune=False)  #Extractor output has dim 768 \n",
    "config = AutoModelForTokenClassification.from_pretrained(model_name).config\n",
    "\n",
    "config.update({'num_labels': 13})\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "        r=64,\n",
    "        lora_alpha=16,\n",
    "        lora_dropout=0.1,\n",
    "        bias=\"none\",\n",
    "        task_type=\"FEATURE_EXTRACTION\",\n",
    "        inference_mode=False,\n",
    "        target_modules=[\"query_proj\", \"key_proj\", \"value_proj\", \"output.dense\"])\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name, config = config, \n",
    "                                                        ignore_mismatched_sizes=True)\n",
    "model = get_peft_model(model, peft_config)\n",
    "\n",
    "# print(model)\n",
    "\n",
    "for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "for param in model.classifier.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Model's trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad): ,}\")\n",
    "print(f\"Model's total parameters: {sum(p.numel() for p in model.parameters()): ,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' \n",
    "model = model.to(device)\n",
    "epochs = 5\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# collator = DataCollatorForTokenClassification(tokenizer, pad_to_multiple_of = 32, max_length=3500)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001, weight_decay=0.0005)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max = epochs)\n",
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split completed\n",
      "trainset loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=3): 100%|██████████| 5785/5785 [00:10<00:00, 532.06 examples/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset mapped\n",
      "valset loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=3): 100%|██████████| 1022/1022 [00:04<00:00, 219.76 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valset mapped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Preparing the datasets for token classification\n",
    "data = json.load(open('data/train.json'))\n",
    "model_name = \"MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "train_data, val_data = train_test_split(data, test_size=0.15, random_state=42)  \n",
    "print('Data split completed')\n",
    "\n",
    "# # Limit to 100 for testing\n",
    "# train_data = train_data[:100]\n",
    "# val_data = val_data[:100]\n",
    "\n",
    "trainset = datasets.Dataset.from_dict({\n",
    "    'full_text': [x['full_text'] for x in train_data],\n",
    "    'document': [x['document'] for x in train_data],\n",
    "    'tokens': [x['tokens'] for x in train_data],\n",
    "    'trailing_whitespace': [x['trailing_whitespace'] for x in train_data],\n",
    "    'labels' :[x['labels'] for x in train_data]\n",
    "    # 'labels' :[oh_encoder(x['labels']) for x in train_data] \n",
    "})\n",
    "print('trainset loaded')\n",
    "\n",
    "trainset = trainset.map(tokenize, fn_kwargs = {\"tokenizer\": tokenizer}, num_proc=3)\n",
    "#train_labels = [oh_encoder(x['labels'] for x in train_data)]\n",
    "print('trainset mapped')\n",
    "\n",
    "# val_labels = [oh_encoder(x['labels']) for x in val_data]\n",
    "\n",
    "valset = datasets.Dataset.from_dict({\n",
    "    'full_text': [x['full_text'] for x in val_data],\n",
    "    'document': [x['document'] for x in val_data],\n",
    "    'tokens': [x['tokens'] for x in val_data],\n",
    "    'trailing_whitespace': [x['trailing_whitespace'] for x in val_data],\n",
    "    'labels' :[x['labels'] for x in val_data]\n",
    "    # 'labels' :[oh_encoder(x['labels']) for x in val_data]\n",
    "})\n",
    "print('valset loaded')\n",
    "\n",
    "valset = valset.map(tokenize, fn_kwargs = {\"tokenizer\": tokenizer}, num_proc=3)\n",
    "print('valset mapped')\n",
    "\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training data: 5785 || Number of validation data: 1022\n"
     ]
    }
   ],
   "source": [
    "#First item\n",
    "print(f\"Number of training data: {len(trainset)} || Number of validation data: {len(valset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Not Required'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Not Required'''\n",
    "# def to_dict(data):\n",
    "#     dict_of_lists = {}\n",
    "#     for d in data:\n",
    "#         for key, value in d.items():\n",
    "#             if key in dict_of_lists:\n",
    "#                 dict_of_lists[key].append(value)\n",
    "#             else:\n",
    "#                 dict_of_lists[key] = [value]\n",
    "#     return dict_of_lists\n",
    "\n",
    "# trainset = to_dict(trainset)\n",
    "# #trainset['labels'] = train_labels\n",
    "\n",
    "# valset = to_dict(valset)\n",
    "# #valset['labels'] = val_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_data(Dataset):\n",
    "    def __init__(self, data_dict):\n",
    "        self.data = data_dict['input_ids']\n",
    "        self.attention_mask = data_dict['attention_mask']\n",
    "        self.labels = data_dict['labels']\n",
    "        self.doc_no = data_dict['document']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.data[idx]), torch.tensor(self.attention_mask[idx]), oh_encoder(self.labels[idx]) , torch.tensor(self.doc_no[idx])\n",
    "\n",
    "custom_train = Custom_data(trainset)\n",
    "custom_val = Custom_data(valset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Uncomment to check'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def custom_collate(batch):\n",
    "    '''\n",
    "    For padding\n",
    "    '''\n",
    "    input_ids, attention_mask, one_hot_labels, document = zip(*batch)\n",
    "    # Pad the input_ids and labels\n",
    "    padded_input_ids = pad_sequence(input_ids, batch_first=True, padding_value=0)\n",
    "    padded_attention_mask = pad_sequence(attention_mask, batch_first = True, padding_value = 0)\n",
    "    padded_labels = pad_sequence(one_hot_labels, batch_first=True, padding_value=0)  \n",
    "    \n",
    "    return padded_input_ids, padded_attention_mask, padded_labels, document\n",
    "\n",
    "batch_size = 2\n",
    "train_dataloader = DataLoader(custom_train, batch_size=batch_size, collate_fn = custom_collate)\n",
    "val_dataloader = DataLoader(custom_val, batch_size=batch_size, collate_fn=custom_collate)\n",
    "\n",
    "'''Uncomment to check'''\n",
    "# for i, (input_ids, attention_mask, labels, doc) in enumerate(val_dataloader):\n",
    "#     print(f'Batch {i + 1}:')\n",
    "#     print('Input IDs:', input_ids.size())\n",
    "#     print('Attention_mask:', attention_mask.size())\n",
    "#     print('Labels:', labels.size())\n",
    "#     print('Document:', doc)\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(model, custom_val, batch_size, custom_collate, criterion, device):\n",
    "    model.eval()\n",
    "\n",
    "    avg_val_loss = 0\n",
    "    avg_val_score = 0\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0\n",
    "        val_score = 0\n",
    "        val_dataloader = DataLoader(custom_val, batch_size = batch_size, collate_fn = custom_collate, shuffle = False)\n",
    "\n",
    "        for batch, (input_ids, attention_mask, labels, doc) in enumerate(val_dataloader):\n",
    "            \n",
    "            input_ids = input_ids.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask).logits\n",
    "            loss = criterion(outputs, labels)\n",
    "            results = compute_metrics(outputs, labels)\n",
    "\n",
    "            val_loss += loss\n",
    "            val_score += results['f5']\n",
    "\n",
    "            if batch%200 == 0 or batch+1 == len(val_dataloader): \n",
    "                print(\"********** For Validation Set **********\")                                                                       \n",
    "                print(f\"Completed {batch+1}/{len(val_dataloader)}, with current val_loss: {loss},\\n current results:{results}\") \n",
    "\n",
    "    avg_val_loss = val_loss / len(custom_val) \n",
    "    avg_val_score = val_score/len(val_dataloader)\n",
    "\n",
    "    print(f\"Average val_loss: {avg_val_loss}, avgerage val_score = {avg_val_score}\")\n",
    "\n",
    "    return avg_val_loss, avg_val_score\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, custom_train, custom_val, batch_size, custom_collate, epochs, optimizer, criterion,  device):\n",
    "    \n",
    "    torch.autograd.profiler.profile(enabled = True, record_shapes = True)\n",
    "    model.train()\n",
    "    best_val_loss = float('inf')\n",
    "    best_val_score = -float('inf')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        avg_train_loss = 0\n",
    "        avg_train_score = 0\n",
    "        train_loss = 0\n",
    "        train_score = 0\n",
    "\n",
    "        \n",
    "        train_dataloader = DataLoader(custom_train, batch_size = batch_size, collate_fn = custom_collate, shuffle = True)\n",
    "        print('Starting training...')\n",
    "        \n",
    "        for batch, (input_ids, attention_mask, labels, doc) in enumerate(train_dataloader):\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            input_ids = input_ids.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask).logits\n",
    "            # print(outputs.size())\n",
    "            # print(labels.size())\n",
    "            \n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "\n",
    "            results = compute_metrics(outputs, labels)\n",
    "            train_loss += loss\n",
    "            train_score+= results['f5']\n",
    "\n",
    "            if batch%200 == 0 or batch+1 == len(train_dataloader):\n",
    "                print(f\"Completed {batch+1}/{len(train_dataloader)}, with current train_loss: {loss},\\n current results:{results}\")\n",
    "\n",
    "        avg_train_loss = train_loss / len(custom_train)    \n",
    "        avg_train_score = train_score / len(train_dataloader)\n",
    "\n",
    "        \n",
    "        print()\n",
    "        print(f\"Epoch {epoch+1}/{epochs}: Average train_loss = {avg_train_loss}, average train_score = {avg_train_score}\")\n",
    "\n",
    "        print()\n",
    "        print(\"Starting to validate\")\n",
    "        val_loss, val_score = val(model, custom_val, batch_size, custom_collate, criterion, device)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'deberta_small_best_loss.pt')\n",
    "\n",
    "        if val_score > best_val_score:\n",
    "            best_val_score = val_score\n",
    "            torch.save(model.state_dict(), 'deberta_small_best_score.pt')\n",
    "        \n",
    "        print(torch.autograd.profiler.summarize())\n",
    "    \n",
    "    torch.autograd.profiler.profile(enabled=False)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Completed 1/724, with current train_loss: 426.57251772055264,\n",
      " current results:{'f5': 0.14364640883977903, 'recall': 0.1875, 'precision': 0.02097902097902098}\n",
      "Completed 201/724, with current train_loss: 523.0646255979171,\n",
      " current results:{'f5': 0.7236305619570998, 'recall': 1.0, 'precision': 0.09149184149184149}\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "epochs = 10\n",
    "\n",
    "train(model, custom_train, custom_val, batch_size, custom_collate, epochs, optimizer, criterion, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, criterion, device, batch_print):\n",
    "    model.train()\n",
    "    \n",
    "    train_loss = 0\n",
    "    avg_train_loss = 0\n",
    "    train_f5 = 0\n",
    "    avg_train_f5 = 0\n",
    "\n",
    "    for idx, (input_ids, attention_mask, labels, doc) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask).logits\n",
    "        loss = criterion(outputs, labels)\n",
    "        print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        train_loss += loss\n",
    "        f5 = compute_metrics(outputs, labels)['f5']\n",
    "        train_f5 += f5\n",
    "        \n",
    "        # if idx%batch_print == 0:\n",
    "        #     print(f\"Completed batch {idx}/{len(train_loader)}, with current train_loss: {loss:.3f}, current f5_score: {f5:.3f}\") \n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader) \n",
    "    avg_train_f5 = train_f5 / len(train_loader)\n",
    "\n",
    "    return avg_train_loss , avg_train_f5\n",
    "\n",
    "\n",
    "def val(model, val_loader, criterion, device, batch_print):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    f5_score = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (input_ids, attention_mask, labels, doc) in enumerate(val_loader):\n",
    "            input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "            outputs = model(input_ids, attention_mask).logits\n",
    "            val_loss += criterion(outputs, labels)\n",
    "            f5_score += compute_metrics(outputs, labels)['f5']\n",
    "            \n",
    "            # if idx%batch_print == 0:\n",
    "            #     print(f\"Completed batch {idx}/{len(val_loader)}, with current train_loss: {criterion(outputs, labels)}\")  \n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    avg_f5 = f5_score / len(val_loader)\n",
    "    \n",
    "    return avg_val_loss, avg_f5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-232978.3374, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<DivBackward1>)\n",
      "tensor(-1094015.7133, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<DivBackward1>)\n",
      "tensor(-73956.7469, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<DivBackward1>)\n",
      "tensor(-80332.6396, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<DivBackward1>)\n",
      "tensor(-1107939.0330, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<DivBackward1>)\n",
      "tensor(-1006790.3859, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<DivBackward1>)\n",
      "tensor(-794905.2011, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<DivBackward1>)\n",
      "tensor(-408227.0229, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<DivBackward1>)\n",
      "tensor(-402571.3800, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<DivBackward1>)\n",
      "tensor(-12715.3878, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<DivBackward1>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m     19\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 21\u001b[0m     train_loss, train_f5 \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_batch_print\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m     val_loss, val_f5 \u001b[38;5;241m=\u001b[39m val(model, val_loader, criterion, device, val_batch_print)\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;66;03m# train_loss = train(model, train_loader, optimizer, criterion, device, train_batch_print)\u001b[39;00m\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;66;03m# val_loss = val(model, val_loader, criterion, device, val_batch_print)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[44], line 15\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, optimizer, criterion, device, batch_print)\u001b[0m\n\u001b[0;32m     13\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(input_ids, attention_mask)\u001b[38;5;241m.\u001b[39mlogits\n\u001b[0;32m     14\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     17\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\nlp\\Lib\\site-packages\\torch\\_tensor.py:461\u001b[0m, in \u001b[0;36mTensor.__repr__\u001b[1;34m(self, tensor_contents)\u001b[0m\n\u001b[0;32m    457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    458\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__repr__\u001b[39m, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, tensor_contents\u001b[38;5;241m=\u001b[39mtensor_contents\n\u001b[0;32m    459\u001b[0m     )\n\u001b[0;32m    460\u001b[0m \u001b[38;5;66;03m# All strings are unicode in Python 3.\u001b[39;00m\n\u001b[1;32m--> 461\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tensor_str\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_contents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_contents\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\nlp\\Lib\\site-packages\\torch\\_tensor_str.py:677\u001b[0m, in \u001b[0;36m_str\u001b[1;34m(self, tensor_contents)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad(), torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39m_python_dispatch\u001b[38;5;241m.\u001b[39m_disable_current_modes():\n\u001b[0;32m    676\u001b[0m     guard \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_DisableFuncTorch()\n\u001b[1;32m--> 677\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_str_intern\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_contents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_contents\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\nlp\\Lib\\site-packages\\torch\\_tensor_str.py:597\u001b[0m, in \u001b[0;36m_str_intern\u001b[1;34m(inp, tensor_contents)\u001b[0m\n\u001b[0;32m    595\u001b[0m                     tensor_str \u001b[38;5;241m=\u001b[39m _tensor_str(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_dense(), indent)\n\u001b[0;32m    596\u001b[0m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 597\u001b[0m                     tensor_str \u001b[38;5;241m=\u001b[39m \u001b[43m_tensor_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout \u001b[38;5;241m!=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstrided:\n\u001b[0;32m    600\u001b[0m     suffixes\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayout=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout))\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\nlp\\Lib\\site-packages\\torch\\_tensor_str.py:349\u001b[0m, in \u001b[0;36m_tensor_str\u001b[1;34m(self, indent)\u001b[0m\n\u001b[0;32m    345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _tensor_str_with_formatter(\n\u001b[0;32m    346\u001b[0m         \u001b[38;5;28mself\u001b[39m, indent, summarize, real_formatter, imag_formatter\n\u001b[0;32m    347\u001b[0m     )\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 349\u001b[0m     formatter \u001b[38;5;241m=\u001b[39m \u001b[43m_Formatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_summarized_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msummarize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    350\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _tensor_str_with_formatter(\u001b[38;5;28mself\u001b[39m, indent, summarize, formatter)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\nlp\\Lib\\site-packages\\torch\\_tensor_str.py:137\u001b[0m, in \u001b[0;36m_Formatter.__init__\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m    134\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_width, \u001b[38;5;28mlen\u001b[39m(value_str))\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 137\u001b[0m     nonzero_finite_vals \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmasked_select\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtensor_view\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misfinite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_view\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m&\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtensor_view\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mne\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nonzero_finite_vals\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;66;03m# no valid number, do nothing\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time \n",
    "device = 'cuda'\n",
    "model = model.to(device)\n",
    "epochs = 10\n",
    "\n",
    "train_loader = train_dataloader\n",
    "val_loader = val_dataloader\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001, weight_decay=0.0005)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max = epochs)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "train_batch_print = 10000\n",
    "val_batch_print = 3000\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "best_valid_f5 = float('inf')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_f5 = train(model, train_loader, optimizer, criterion, device, train_batch_print)\n",
    "    val_loss, val_f5 = val(model, val_loader, criterion, device, val_batch_print)\n",
    "\n",
    "    # train_loss = train(model, train_loader, optimizer, criterion, device, train_batch_print)\n",
    "    # val_loss = val(model, val_loader, criterion, device, val_batch_print)\n",
    "    \n",
    "    if val_loss < best_valid_loss:\n",
    "        best_valid_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'model_best_loss_CE.pt')\n",
    "    if val_f5 > best_valid_f5:\n",
    "        best_valid_f5 = val_f5\n",
    "        torch.save(model.state_dict(), 'model_best_f5_CE.pt')\n",
    "    \n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    print(f'Epoch: {epoch+1:02} | training loss: {train_loss:.3f} | val loss: {val_loss:.3f} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'train f5: {train_f5:.3f} | val f5: {val_f5:.3f} | Ending time: {end_time}')\n",
    "    print('========'*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting from predictions to NER labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Used to label each token at NER stage\n",
    "def find_span(target: list[str], document: list[str]) -> list[list[int]]:\n",
    "    \n",
    "    idx = 0\n",
    "    spans = []\n",
    "    span = []\n",
    "\n",
    "    for i, token in enumerate(document):\n",
    "        if token != target[idx]:\n",
    "            idx = 0\n",
    "            span = []\n",
    "            continue\n",
    "        span.append(i)\n",
    "        idx += 1\n",
    "        if idx == len(target):\n",
    "            spans.append(span)\n",
    "            span = []\n",
    "            idx = 0\n",
    "            continue\n",
    "    \n",
    "    return spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DON'T RUN ##\n",
    "#### From KAGGLE: https://www.kaggle.com/code/manavtrivedi/0-967-nlp-sakura/notebook ####\n",
    "\n",
    "triplets = []\n",
    "pairs = set()  # membership operation using set is faster O(1) than that of list O(n)\n",
    "processed = []\n",
    "emails = []\n",
    "phone_nums = []\n",
    "urls = []\n",
    "streets = []\n",
    "\n",
    "# For each prediction, token mapping, offsets, tokens, and document in the dataset\n",
    "for p, token_map, offsets, tokens, doc, full_text in zip(\n",
    "    preds_final, \n",
    "    ds[\"token_map\"], \n",
    "    ds[\"offset_mapping\"], \n",
    "    ds[\"tokens\"], \n",
    "    ds[\"document\"],\n",
    "    ds[\"full_text\"]\n",
    "):\n",
    "\n",
    "    # Iterate through each token prediction and its corresponding offsets\n",
    "    for token_pred, (start_idx, end_idx) in zip(p, offsets):\n",
    "        label_pred = id2label[str(token_pred)]  # Predicted label from token\n",
    "        if start_idx + end_idx == 0:\n",
    "            continue\n",
    "        if token_map[start_idx] == -1:\n",
    "            start_idx += 1\n",
    "        while start_idx < len(token_map) and tokens[token_map[start_idx]].isspace():\n",
    "            start_idx += 1\n",
    "        if start_idx >= len(token_map):\n",
    "            break\n",
    "        token_id = token_map[start_idx]  # Token ID at start index\n",
    "        if label_pred in (\"O\", \"B-EMAIL\", \"B-PHONE_NUM\", \"I-PHONE_NUM\") or token_id == -1:\n",
    "            continue\n",
    "        pair = (doc, token_id)\n",
    "        if pair not in pairs:\n",
    "            processed.append({\"document\": doc, \"token\": token_id, \"label\": label_pred, \"token_str\": tokens[token_id]})\n",
    "            pairs.add(pair)\n",
    "    \n",
    "    # email\n",
    "    for token_idx, token in enumerate(tokens):\n",
    "        if re.fullmatch(email_regex, token) is not None:\n",
    "            emails.append(\n",
    "                {\"document\": doc, \"token\": token_idx, \"label\": \"B-EMAIL\", \"token_str\": token}\n",
    "            )\n",
    "                \n",
    "    # phone number\n",
    "    matches = phone_num_regex.findall(full_text)\n",
    "    if not matches:\n",
    "        continue\n",
    "    for match in matches:\n",
    "        target = [t.text for t in nlp.tokenizer(match)]\n",
    "        matched_spans = find_span(target, tokens)\n",
    "    for matched_span in matched_spans:\n",
    "        for intermediate, token_idx in enumerate(matched_span):\n",
    "            prefix = \"I\" if intermediate else \"B\"\n",
    "            phone_nums.append(\n",
    "                {\"document\": doc, \"token\": token_idx, \"label\": f\"{prefix}-PHONE_NUM\", \"token_str\": tokens[token_idx]}\n",
    "            )\n",
    "    \n",
    "    # url\n",
    "    matches = url_regex.findall(full_text)\n",
    "    if not matches:\n",
    "        continue\n",
    "    for match in matches:\n",
    "        target = [t.text for t in nlp.tokenizer(match)]\n",
    "        matched_spans = find_span(target, tokens)\n",
    "    for matched_span in matched_spans:\n",
    "        for intermediate, token_idx in enumerate(matched_span):\n",
    "            prefix = \"I\" if intermediate else \"B\"\n",
    "            urls.append(\n",
    "                {\"document\": doc, \"token\": token_idx, \"label\": f\"{prefix}-URL_PERSONAL\", \"token_str\": tokens[token_idx]}\n",
    "            )\n",
    "    \n",
    "    # street\n",
    "#     matches = street_regex.findall(full_text)\n",
    "#     if not matches:\n",
    "#         continue\n",
    "#     for match in matches:\n",
    "#         target = [t.text for t in nlp.tokenizer(match)]\n",
    "#         matched_spans = find_span(target, tokens)\n",
    "#     for matched_span in matched_spans:\n",
    "#         for intermediate, token_idx in enumerate(matched_span):\n",
    "#             prefix = \"I\" if intermediate else \"B\"\n",
    "#             streets.append(\n",
    "#                 {\"document\": doc, \"token\": token_idx, \"label\": f\"{prefix}-STREET_ADDRESS\", \"token_str\": tokens[token_idx]}\n",
    "#             )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
