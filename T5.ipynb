{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDYo500GP0lF"
      },
      "source": [
        "**Some references**\n",
        "\n",
        "https://www.kaggle.com/code/minhsienweng/train-infer-pii-detection-deberta-v3\n",
        "\n",
        "(no training) https://www.kaggle.com/code/manavtrivedi/0-967-nlp-sakura/notebook"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-ignite\n",
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMV4v4rGWSPu",
        "outputId": "e2abca88-b5f2-41ce-bdb5-fcf8096be525"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch-ignite in /usr/local/lib/python3.10/dist-packages (0.5.0.post2)\n",
            "Requirement already satisfied: torch<3,>=1.3 in /usr/local/lib/python3.10/dist-packages (from pytorch-ignite) (2.2.1+cu121)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytorch-ignite) (24.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.3->pytorch-ignite) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.3->pytorch-ignite) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.3->pytorch-ignite) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.3->pytorch-ignite) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.3->pytorch-ignite) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.3->pytorch-ignite) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.3->pytorch-ignite) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.3->pytorch-ignite) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.3->pytorch-ignite) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.3->pytorch-ignite) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.3->pytorch-ignite) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.3->pytorch-ignite) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.3->pytorch-ignite) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.3->pytorch-ignite) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.3->pytorch-ignite) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.3->pytorch-ignite) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.3->pytorch-ignite) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.3->pytorch-ignite) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<3,>=1.3->pytorch-ignite) (12.4.127)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<3,>=1.3->pytorch-ignite) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<3,>=1.3->pytorch-ignite) (1.3.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.18.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install peft"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jxXYD-QXo5k",
        "outputId": "79e1a53d-5e84-4238-c145-d631ebba22b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.10.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.2.1+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.38.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.66.2)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.29.2)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (3.13.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.15.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6__3vASP0lG"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import datasets\n",
        "import tqdm\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification, DataCollatorForTokenClassification, Trainer, TrainingArguments\n",
        "from scipy.special import softmax\n",
        "from sklearn.model_selection import train_test_split\n",
        "from spacy.lang.en import English\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from ignite.metrics import Fbeta\n",
        "from functools import partial\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from sklearn.metrics import recall_score, precision_score\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from torch.nn.functional import softmax\n",
        "from peft import get_peft_model, LoraConfig"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Kaggle API\n",
        "!pip install kaggle\n",
        "# Upload Kaggle API key\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "# Set up Kaggle API credentials\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle competitions download -c pii-detection-removal-from-educational-data\n",
        "!unzip pii-detection-removal-from-educational-data.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "YvUOgyLNYxa3",
        "outputId": "7076dda5-cab0-47c4-b33e-61d425a8582f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.16)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.2)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.6)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-bbd44219-ac63-4407-b69b-a363d87c9bf6\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-bbd44219-ac63-4407-b69b-a363d87c9bf6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle (1).json\n",
            "pii-detection-removal-from-educational-data.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Archive:  pii-detection-removal-from-educational-data.zip\n",
            "replace sample_submission.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: sample_submission.csv   \n",
            "replace test.json? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: test.json               \n",
            "replace train.json? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: train.json              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4uvLtUhP0lH"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MN2eOKHyP0lH",
        "outputId": "eec8a107-44c8-4386-d70d-d67d131128f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13 labels, with the following labels:\n",
            " ['B-NAME_STUDENT', 'I-NAME_STUDENT', 'B-ID_NUM', 'I-ID_NUM', 'O', 'I-URL_PERSONAL', 'I-PHONE_NUM', 'B-PHONE_NUM', 'B-STREET_ADDRESS', 'B-URL_PERSONAL', 'B-USERNAME', 'B-EMAIL', 'I-STREET_ADDRESS']\n"
          ]
        }
      ],
      "source": [
        "#Finding out the number of labels\n",
        "data = json.load(open('train.json'))\n",
        "\n",
        "all_labels = set()\n",
        "\n",
        "for d in data:\n",
        "    all_labels = all_labels.union(set(d['labels']))\n",
        "\n",
        "print(f\"{len(list(all_labels))} labels, with the following labels:\\n {list(all_labels)}\")\n",
        "del data\n",
        "\n",
        "label2id = {label:index for index,label in enumerate(all_labels)}\n",
        "id2label = {index:label for index,label in enumerate(all_labels)}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6IcQlTdmP0lH",
        "outputId": "41b36350-60bb-4b7d-ba05-a63e3b2732a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'B-NAME_STUDENT', 'I-NAME_STUDENT', 'B-ID_NUM', 'I-ID_NUM', 'O', 'I-URL_PERSONAL', 'I-PHONE_NUM', 'B-PHONE_NUM', 'B-STREET_ADDRESS', 'B-URL_PERSONAL', 'B-USERNAME', 'B-EMAIL', 'I-STREET_ADDRESS'}\n"
          ]
        }
      ],
      "source": [
        "print(all_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kXBrx4JcP0lH"
      },
      "outputs": [],
      "source": [
        "#Change to one-hot vector\n",
        "def oh_encoder(labels):  #label: array of output for each sentence\n",
        "\n",
        "    # unique_labels = ['O', 'B-NAME_STUDENT','I-NAME_STUDENT','B-PHONE_NUM', 'I-PHONE_NUM','B-ID_NUM', 'I-ID_NUM',  'B-URL_PERSONAL','I-URL_PERSONAL',\n",
        "    #                   'B-STREET_ADDRESS', 'I-STREET_ADDRESS',  'B-EMAIL', 'B-USERNAME']\n",
        "\n",
        "\n",
        "    unique_labels = ['O', 'B-NAME_STUDENT','I-NAME_STUDENT','B-URL_PERSONAL', 'B-ID_NUM','I-ID_NUM','B-EMAIL','I-STREET_ADDRESS',\n",
        "                     'I-PHONE_NUM', 'B-USERNAME', 'B-PHONE_NUM','B-STREET_ADDRESS', 'I-URL_PERSONAL']\n",
        "\n",
        "    labels_oh = []\n",
        "    for label in labels:    #label: str\n",
        "        label_oh = [float(0)]*len(unique_labels)\n",
        "        for k in range(len(unique_labels)):\n",
        "            if unique_labels[k] == label:\n",
        "                label_oh[k] = 1\n",
        "                #labels_oh.append(torch.tensor(label_oh, requires_grad=True))\n",
        "                labels_oh.append(label_oh)\n",
        "                break\n",
        "\n",
        "\n",
        "    #return torch.tensor(labels_oh, requires_grad=True)\n",
        "    return torch.tensor(labels_oh, requires_grad=True, dtype=float)    #list of one-hot labels as tensors\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OT7GO72UP0lH"
      },
      "outputs": [],
      "source": [
        "def tokenize(example, tokenizer):\n",
        "    import numpy as np\n",
        "    # Preprocess the tokens and labels by adding trailing whitespace and labels\n",
        "    tokens = []\n",
        "    labels = []\n",
        "    for token, label, t_ws in zip(example[\"tokens\"],\n",
        "                                  example[\"labels\"],\n",
        "                                  example[\"trailing_whitespace\"]):\n",
        "        tokens.append(token)\n",
        "        labels.extend([label] * len(token))\n",
        "        # Added trailing whitespace and label if true and\n",
        "        if t_ws:\n",
        "            tokens.append(\" \")\n",
        "            # labels.append(oh_encoder(\"O\"))\n",
        "            labels.append(\"O\")\n",
        "\n",
        "    text = \"\".join(tokens)\n",
        "    # print(f\"len(text)={len(text)}, len(tokens)={len(tokens)}\")\n",
        "    # tokenization without truncation\n",
        "    tokenized = tokenizer(text, return_offsets_mapping=True,\n",
        "                          truncation=False)\n",
        "    #labels = np.array(labels)\n",
        "    # Labels\n",
        "    token_labels = []\n",
        "    for start_idx, end_idx in tokenized.offset_mapping:\n",
        "        # Added 'O'\n",
        "        if start_idx == 0 and end_idx == 0:\n",
        "            #token_labels.append(label2id[\"O\"])\n",
        "            #token_labels.append(oh_encoder(\"O\"))\n",
        "            token_labels.append(\"O\")\n",
        "        else:\n",
        "            # case when the text starts with whitespace\n",
        "            if text[start_idx].isspace():\n",
        "                start_idx += 1\n",
        "            # Convert label to id (int)\n",
        "            #label_id = label2id[labels[start_idx]]\n",
        "            label_id = labels[start_idx]\n",
        "            #token_labels.append(oh_encoder(label_id))\n",
        "            token_labels.append(label_id)\n",
        "\n",
        "    return {**tokenized, \"labels\": token_labels, \"length\": len(tokenized.input_ids)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ku5VDtwbP0lI"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(outputs, labels, unique_labels = ['O', 'B-NAME_STUDENT','I-NAME_STUDENT','B-URL_PERSONAL',\n",
        "                                                          'B-ID_NUM','I-ID_NUM','B-EMAIL','I-STREET_ADDRESS',\n",
        "                                                          'I-PHONE_NUM', 'B-USERNAME', 'B-PHONE_NUM','B-STREET_ADDRESS', 'I-URL_PERSONAL']):\n",
        "    try:\n",
        "        #print(\"Compute metrics\")\n",
        "        predictions = torch.argmax(softmax(outputs, dim=2), dim=2)\n",
        "        # Include prediction Remove ignored index (special tokens)\n",
        "        true_preds = []\n",
        "        true_labels = []\n",
        "        for pred, label in zip(predictions, labels):\n",
        "            true_preds.append([unique_labels[p] for p, l in zip(pred, label) if l[0] != -100])\n",
        "            true_labels.append([unique_labels[torch.argmax(l)] for p, l in zip(pred, label) if l[0] != -100])\n",
        "\n",
        "        mlb = MultiLabelBinarizer(classes=unique_labels)\n",
        "        true_preds_bin = mlb.fit_transform(true_preds)\n",
        "        true_labels_bin = mlb.transform(true_labels)\n",
        "        # Compute recall, precision and f5 score\n",
        "        recall = recall_score(true_labels_bin, true_preds_bin, average='samples')\n",
        "        precision = precision_score(true_labels_bin, true_preds_bin, average='samples')\n",
        "        # Use modified f5 score to measure the performance\n",
        "        f5_score = (1 + 5*5) * (recall * precision / (5*5*precision + recall))\n",
        "        result = {'f5': f5_score,\n",
        "                  'recall': recall,\n",
        "                  'precision': precision}\n",
        "        # print(f\"result = {result}\")\n",
        "        return result\n",
        "    except Exception as e:\n",
        "        print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a03sd6GBP0lI"
      },
      "outputs": [],
      "source": [
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=1, gamma=2, num_classes=len(all_labels)):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        mask = (targets != -100).float()\n",
        "        targets = targets.clamp(min=0)\n",
        "        #targets = F.one_hot(targets, num_classes=self.num_classes).float()\n",
        "\n",
        "        BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
        "        pt = torch.exp(-BCE_loss)\n",
        "        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n",
        "\n",
        "        # F_loss = F_loss.mean(dim=1)\n",
        "        F_loss = torch.mul(F_loss, mask).mean(dim=1)\n",
        "\n",
        "        return F_loss.sum()/mask.sum()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5zeNl1HP0lI"
      },
      "source": [
        "# Model: T5\n",
        "\n",
        "Using a pretrained T5 (small), we will build a classifier head on top of it to predict the class at token level."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XI7jZvuQP0lI"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import T5TokenizerFast, T5ForTokenClassification\n",
        "import torch"
      ],
      "metadata": {
        "id": "vXLDcy9pZrBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBAhWUTBP0lI",
        "outputId": "4eafc62e-48c6-4a59-d09d-403222361bbb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of T5ForTokenClassification were not initialized from the model checkpoint at google-t5/t5-small and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of T5ForTokenClassification were not initialized from the model checkpoint at google-t5/t5-small and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model's trainable parameters:  6,669\n",
            "Model's total parameters:  36,123,917\n"
          ]
        }
      ],
      "source": [
        "from transformers import BitsAndBytesConfig\n",
        "\n",
        "\n",
        "tokenizer = T5TokenizerFast.from_pretrained(\"google-t5/t5-small\")\n",
        "\n",
        "#config = T5ForTokenClassification.from_pretrained(\"google-t5/t5-small\").config\n",
        "\n",
        "config = AutoModelForTokenClassification.from_pretrained(\"google-t5/t5-small\").config\n",
        "\n",
        "config.update({'num_labels': 13})\n",
        "\n",
        "peft_config = LoraConfig(\n",
        "        r=64,\n",
        "        lora_alpha=16,\n",
        "        lora_dropout=0.1,\n",
        "        bias=\"none\",\n",
        "        task_type=\"FEATURE_EXTRACTION\",\n",
        "        inference_mode=False)\n",
        "        #target_modules=[\"query_proj\", \"key_proj\", \"value_proj\", \"output.dense\"])\n",
        "\n",
        "\n",
        "# bnb_config = BitsAndBytesConfig(\n",
        "#                 load_in_4bit=True,\n",
        "#                 bnb_4bit_quant_type=\"nf4\",\n",
        "#                 bnb_4bit_use_double_quant=False,\n",
        "#                 bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "#                 llm_int8_skip_modules=['classifier']\n",
        "#             )\n",
        "\n",
        "#bnb_config = BitsAndBytesConfig(\n",
        " #       load_in_8bit=True,\n",
        "  #      llm_int8_skip_modules=['classifier']\n",
        "#)\n",
        "\n",
        "#model = T5ForTokenClassification.from_pretrained(\"google-t5/t5-small\", ignore_mismatched_sizes=True)\n",
        "model = AutoModelForTokenClassification.from_pretrained(\"google-t5/t5-small\", config = config,\n",
        "                                                        ignore_mismatched_sizes=True)\n",
        "                                                        #quantization_config=bnb_config)\n",
        "model = get_peft_model(model, peft_config)\n",
        "\n",
        "# print(model)\n",
        "\n",
        "for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "for param in model.classifier.parameters():\n",
        "        param.requires_grad = True\n",
        "\n",
        "\n",
        "\n",
        "print(f\"Model's trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad): ,}\")\n",
        "print(f\"Model's total parameters: {sum(p.numel() for p in model.parameters()): ,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQfqGCkvP0lJ"
      },
      "outputs": [],
      "source": [
        "device = 'cuda'\n",
        "model = model.to(device)\n",
        "epochs = 5\n",
        "##tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "# collator = DataCollatorForTokenClassification(tokenizer, pad_to_multiple_of = 32, max_length=3500)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001, weight_decay=0.0005)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max = epochs)\n",
        "#criterion = nn.CrossEntropyLoss().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NetdKIPqP0lJ",
        "outputId": "ad07fbb1-39e4-468e-e24d-954afbea8b09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297,
          "referenced_widgets": [
            "f2206b9a9fe641b9a723f30b07a1e435",
            "08839243a92f4a55a9c79573c54e34e9",
            "7f850617a1244e8c847599cfe3d9864d",
            "bbd2e8350d8a432da85cf9d1a2c183dd",
            "d43e2ac16a734dda8a0e918c463c1ad2",
            "aec0dd539324488ab0bda7e20fb5e4ee",
            "6c5a6c4de11a4cdca36b842148ff1f60",
            "c80fbe0e7ccc49cca7545def9ae6d0f9",
            "5c23a733d360454087c8b51862ef2573",
            "934d8a50afe94ec5aa281a71a0dd835f",
            "baa2afc3a2724969b0b170403e0f96d0",
            "7b75520d32464159aaf1df18a5d79557",
            "2845269df4af4d969f55ff24fcb22d6c",
            "633cf20038dd4c2a83c54f3bc83c076b",
            "b3550a6e502e4a879d976b058aee08f4",
            "a5949a52513341a8bcefec74813a0975",
            "a140a9d5f8494b74aae44b6559a35612",
            "ef189afc4e064787a1ad4f503dc66f77",
            "c3992ca9a85849ea9b807e6d2f36120a",
            "658044d033914f9f8899b08733afd0a7",
            "c7ed24318c5d44adb938faf7353c47a6",
            "07234c7b51544c27a05ecffa91cddfbb"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data split completed\n",
            "trainset loaded\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=3):   0%|          | 0/5785 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f2206b9a9fe641b9a723f30b07a1e435"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (700 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (712 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (927 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainset mapped\n",
            "valset loaded\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=3):   0%|          | 0/1022 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7b75520d32464159aaf1df18a5d79557"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (603 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (859 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (771 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valset mapped\n"
          ]
        }
      ],
      "source": [
        "#Preparing the datasets for token classification\n",
        "data = json.load(open('train.json'))\n",
        "##model_name = \"MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli\"\n",
        "##tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "train_data, val_data = train_test_split(data, test_size=0.15, random_state=42)\n",
        "print('Data split completed')\n",
        "\n",
        "# # Limit to 100 for testing\n",
        "#train_data = train_data[:100]\n",
        "#val_data = val_data[:100]\n",
        "\n",
        "trainset = datasets.Dataset.from_dict({\n",
        "    'full_text': [x['full_text'] for x in train_data],\n",
        "    'document': [x['document'] for x in train_data],\n",
        "    'tokens': [x['tokens'] for x in train_data],\n",
        "    'trailing_whitespace': [x['trailing_whitespace'] for x in train_data],\n",
        "    'labels' :[x['labels'] for x in train_data]\n",
        "    # 'labels' :[oh_encoder(x['labels']) for x in train_data]\n",
        "})\n",
        "print('trainset loaded')\n",
        "\n",
        "trainset = trainset.map(tokenize, fn_kwargs = {\"tokenizer\": tokenizer}, num_proc=3)\n",
        "#train_labels = [oh_encoder(x['labels'] for x in train_data)]\n",
        "print('trainset mapped')\n",
        "\n",
        "# val_labels = [oh_encoder(x['labels']) for x in val_data]\n",
        "\n",
        "valset = datasets.Dataset.from_dict({\n",
        "    'full_text': [x['full_text'] for x in val_data],\n",
        "    'document': [x['document'] for x in val_data],\n",
        "    'tokens': [x['tokens'] for x in val_data],\n",
        "    'trailing_whitespace': [x['trailing_whitespace'] for x in val_data],\n",
        "    'labels' :[x['labels'] for x in val_data]\n",
        "    # 'labels' :[oh_encoder(x['labels']) for x in val_data]\n",
        "})\n",
        "print('valset loaded')\n",
        "\n",
        "valset = valset.map(tokenize, fn_kwargs = {\"tokenizer\": tokenizer}, num_proc=3)\n",
        "print('valset mapped')\n",
        "\n",
        "del data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rcTRlA6mP0lJ",
        "outputId": "6db63258-4a3d-43e9-93d8-52585f367f7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training data: 5785 || Number of validation data: 1022\n"
          ]
        }
      ],
      "source": [
        "#First item\n",
        "print(f\"Number of training data: {len(trainset)} || Number of validation data: {len(valset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WeMMxTvFP0lJ",
        "outputId": "45fab912-97a6-4140-806f-7e7971b53a8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Not Required'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "'''Not Required'''\n",
        "# def to_dict(data):\n",
        "#     dict_of_lists = {}\n",
        "#     for d in data:\n",
        "#         for key, value in d.items():\n",
        "#             if key in dict_of_lists:\n",
        "#                 dict_of_lists[key].append(value)\n",
        "#             else:\n",
        "#                 dict_of_lists[key] = [value]\n",
        "#     return dict_of_lists\n",
        "\n",
        "# trainset = to_dict(trainset)\n",
        "# #trainset['labels'] = train_labels\n",
        "\n",
        "# valset = to_dict(valset)\n",
        "# #valset['labels'] = val_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hg9Ae3I8P0lJ"
      },
      "outputs": [],
      "source": [
        "class Custom_data(Dataset):\n",
        "    def __init__(self, data_dict):\n",
        "        self.data = data_dict['input_ids']\n",
        "        self.attention_mask = data_dict['attention_mask']\n",
        "        self.labels = data_dict['labels']\n",
        "        self.doc_no = data_dict['document']\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.tensor(self.data[idx]), torch.tensor(self.attention_mask[idx]), oh_encoder(self.labels[idx]) , torch.tensor(self.doc_no[idx])\n",
        "\n",
        "custom_train = Custom_data(trainset)\n",
        "custom_val = Custom_data(valset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EsQgSgABP0lJ"
      },
      "outputs": [],
      "source": [
        "def custom_collate(batch):\n",
        "    '''\n",
        "    For padding\n",
        "    '''\n",
        "    input_ids, attention_mask, one_hot_labels, document = zip(*batch)\n",
        "    # Pad the input_ids and labels\n",
        "    padded_input_ids = pad_sequence(input_ids, batch_first=True, padding_value=0)\n",
        "    padded_attention_mask = pad_sequence(attention_mask, batch_first = True, padding_value = 0)\n",
        "    padded_labels = pad_sequence(one_hot_labels, batch_first=True, padding_value=-100)\n",
        "\n",
        "    return padded_input_ids, padded_attention_mask, padded_labels, document\n",
        "\n",
        "batch_size = 8\n",
        "train_dataloader = DataLoader(custom_train, batch_size=batch_size, collate_fn = custom_collate)\n",
        "val_dataloader = DataLoader(custom_val, batch_size=batch_size, collate_fn=custom_collate)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''Uncomment to check'''\n",
        "for i, (input_ids, attention_mask, labels, doc) in enumerate(val_dataloader):\n",
        "     print(f'Batch {i + 1}:')\n",
        "     print('Input IDs:', input_ids.size())\n",
        "     print('Attention_mask:', attention_mask.size())\n",
        "     print('Labels:', labels.size())\n",
        "     print('Document:', doc)\n",
        "     print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7IK7e-koE6u",
        "outputId": "0e05dbf5-66c6-4f63-e21a-004d7f5d2ade"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 1:\n",
            "Input IDs: torch.Size([8, 1010])\n",
            "Attention_mask: torch.Size([8, 1010])\n",
            "Labels: torch.Size([8, 1010, 13])\n",
            "Document: (tensor(17809), tensor(11144), tensor(16158), tensor(9980), tensor(17676), tensor(20173), tensor(10494), tensor(14012))\n",
            "\n",
            "Batch 2:\n",
            "Input IDs: torch.Size([8, 1395])\n",
            "Attention_mask: torch.Size([8, 1395])\n",
            "Labels: torch.Size([8, 1395, 13])\n",
            "Document: (tensor(8593), tensor(22104), tensor(20242), tensor(10762), tensor(20529), tensor(4899), tensor(8849), tensor(13131))\n",
            "\n",
            "Batch 3:\n",
            "Input IDs: torch.Size([8, 2212])\n",
            "Attention_mask: torch.Size([8, 2212])\n",
            "Labels: torch.Size([8, 2212, 13])\n",
            "Document: (tensor(15076), tensor(13209), tensor(8612), tensor(16882), tensor(16916), tensor(20336), tensor(21008), tensor(10877))\n",
            "\n",
            "Batch 4:\n",
            "Input IDs: torch.Size([8, 1524])\n",
            "Attention_mask: torch.Size([8, 1524])\n",
            "Labels: torch.Size([8, 1524, 13])\n",
            "Document: (tensor(8229), tensor(17787), tensor(19041), tensor(16583), tensor(11136), tensor(17544), tensor(3686), tensor(13706))\n",
            "\n",
            "Batch 5:\n",
            "Input IDs: torch.Size([8, 1247])\n",
            "Attention_mask: torch.Size([8, 1247])\n",
            "Labels: torch.Size([8, 1247, 13])\n",
            "Document: (tensor(4936), tensor(15226), tensor(19425), tensor(11068), tensor(8491), tensor(21598), tensor(22261), tensor(9134))\n",
            "\n",
            "Batch 6:\n",
            "Input IDs: torch.Size([8, 1055])\n",
            "Attention_mask: torch.Size([8, 1055])\n",
            "Labels: torch.Size([8, 1055, 13])\n",
            "Document: (tensor(20222), tensor(4214), tensor(18259), tensor(11939), tensor(14583), tensor(12641), tensor(19348), tensor(10446))\n",
            "\n",
            "Batch 7:\n",
            "Input IDs: torch.Size([8, 2780])\n",
            "Attention_mask: torch.Size([8, 2780])\n",
            "Labels: torch.Size([8, 2780, 13])\n",
            "Document: (tensor(13474), tensor(22141), tensor(7745), tensor(8545), tensor(14866), tensor(9219), tensor(2995), tensor(22518))\n",
            "\n",
            "Batch 8:\n",
            "Input IDs: torch.Size([8, 1023])\n",
            "Attention_mask: torch.Size([8, 1023])\n",
            "Labels: torch.Size([8, 1023, 13])\n",
            "Document: (tensor(17405), tensor(8794), tensor(22192), tensor(11984), tensor(9362), tensor(19937), tensor(13447), tensor(22154))\n",
            "\n",
            "Batch 9:\n",
            "Input IDs: torch.Size([8, 2324])\n",
            "Attention_mask: torch.Size([8, 2324])\n",
            "Labels: torch.Size([8, 2324, 13])\n",
            "Document: (tensor(20660), tensor(21932), tensor(12027), tensor(16157), tensor(10559), tensor(5001), tensor(13697), tensor(10483))\n",
            "\n",
            "Batch 10:\n",
            "Input IDs: torch.Size([8, 1234])\n",
            "Attention_mask: torch.Size([8, 1234])\n",
            "Labels: torch.Size([8, 1234, 13])\n",
            "Document: (tensor(8989), tensor(13638), tensor(14521), tensor(13695), tensor(11491), tensor(22167), tensor(10540), tensor(11807))\n",
            "\n",
            "Batch 11:\n",
            "Input IDs: torch.Size([8, 1538])\n",
            "Attention_mask: torch.Size([8, 1538])\n",
            "Labels: torch.Size([8, 1538, 13])\n",
            "Document: (tensor(16243), tensor(21826), tensor(17035), tensor(1325), tensor(20384), tensor(14606), tensor(16391), tensor(15062))\n",
            "\n",
            "Batch 12:\n",
            "Input IDs: torch.Size([8, 1027])\n",
            "Attention_mask: torch.Size([8, 1027])\n",
            "Labels: torch.Size([8, 1027, 13])\n",
            "Document: (tensor(13083), tensor(12857), tensor(12009), tensor(22190), tensor(22075), tensor(20708), tensor(17011), tensor(11443))\n",
            "\n",
            "Batch 13:\n",
            "Input IDs: torch.Size([8, 1399])\n",
            "Attention_mask: torch.Size([8, 1399])\n",
            "Labels: torch.Size([8, 1399, 13])\n",
            "Document: (tensor(18449), tensor(19274), tensor(10978), tensor(10194), tensor(16659), tensor(13763), tensor(10373), tensor(19738))\n",
            "\n",
            "Batch 14:\n",
            "Input IDs: torch.Size([8, 1550])\n",
            "Attention_mask: torch.Size([8, 1550])\n",
            "Labels: torch.Size([8, 1550, 13])\n",
            "Document: (tensor(13527), tensor(14132), tensor(22466), tensor(21867), tensor(21266), tensor(17188), tensor(6769), tensor(19163))\n",
            "\n",
            "Batch 15:\n",
            "Input IDs: torch.Size([8, 1561])\n",
            "Attention_mask: torch.Size([8, 1561])\n",
            "Labels: torch.Size([8, 1561, 13])\n",
            "Document: (tensor(16089), tensor(11450), tensor(18930), tensor(9494), tensor(15333), tensor(17607), tensor(9560), tensor(16216))\n",
            "\n",
            "Batch 16:\n",
            "Input IDs: torch.Size([8, 1225])\n",
            "Attention_mask: torch.Size([8, 1225])\n",
            "Labels: torch.Size([8, 1225, 13])\n",
            "Document: (tensor(11303), tensor(14563), tensor(18011), tensor(16952), tensor(13542), tensor(7176), tensor(13082), tensor(13936))\n",
            "\n",
            "Batch 17:\n",
            "Input IDs: torch.Size([8, 1850])\n",
            "Attention_mask: torch.Size([8, 1850])\n",
            "Labels: torch.Size([8, 1850, 13])\n",
            "Document: (tensor(16031), tensor(4317), tensor(11145), tensor(19812), tensor(10891), tensor(21034), tensor(12538), tensor(19712))\n",
            "\n",
            "Batch 18:\n",
            "Input IDs: torch.Size([8, 986])\n",
            "Attention_mask: torch.Size([8, 986])\n",
            "Labels: torch.Size([8, 986, 13])\n",
            "Document: (tensor(20815), tensor(22329), tensor(17057), tensor(20850), tensor(15939), tensor(15513), tensor(12899), tensor(8762))\n",
            "\n",
            "Batch 19:\n",
            "Input IDs: torch.Size([8, 1657])\n",
            "Attention_mask: torch.Size([8, 1657])\n",
            "Labels: torch.Size([8, 1657, 13])\n",
            "Document: (tensor(10885), tensor(10220), tensor(11117), tensor(19358), tensor(22622), tensor(20108), tensor(11761), tensor(17362))\n",
            "\n",
            "Batch 20:\n",
            "Input IDs: torch.Size([8, 1133])\n",
            "Attention_mask: torch.Size([8, 1133])\n",
            "Labels: torch.Size([8, 1133, 13])\n",
            "Document: (tensor(21712), tensor(10097), tensor(13066), tensor(7548), tensor(18347), tensor(8787), tensor(11644), tensor(13060))\n",
            "\n",
            "Batch 21:\n",
            "Input IDs: torch.Size([8, 1336])\n",
            "Attention_mask: torch.Size([8, 1336])\n",
            "Labels: torch.Size([8, 1336, 13])\n",
            "Document: (tensor(20399), tensor(14775), tensor(20640), tensor(20758), tensor(10882), tensor(16024), tensor(12585), tensor(14155))\n",
            "\n",
            "Batch 22:\n",
            "Input IDs: torch.Size([8, 1067])\n",
            "Attention_mask: torch.Size([8, 1067])\n",
            "Labels: torch.Size([8, 1067, 13])\n",
            "Document: (tensor(14080), tensor(19555), tensor(14767), tensor(11501), tensor(17969), tensor(19503), tensor(20892), tensor(16180))\n",
            "\n",
            "Batch 23:\n",
            "Input IDs: torch.Size([8, 1012])\n",
            "Attention_mask: torch.Size([8, 1012])\n",
            "Labels: torch.Size([8, 1012, 13])\n",
            "Document: (tensor(10418), tensor(15053), tensor(18883), tensor(22362), tensor(12384), tensor(19018), tensor(12869), tensor(15205))\n",
            "\n",
            "Batch 24:\n",
            "Input IDs: torch.Size([8, 1920])\n",
            "Attention_mask: torch.Size([8, 1920])\n",
            "Labels: torch.Size([8, 1920, 13])\n",
            "Document: (tensor(18552), tensor(16966), tensor(17648), tensor(10995), tensor(11436), tensor(13520), tensor(9802), tensor(19912))\n",
            "\n",
            "Batch 25:\n",
            "Input IDs: torch.Size([8, 1125])\n",
            "Attention_mask: torch.Size([8, 1125])\n",
            "Labels: torch.Size([8, 1125, 13])\n",
            "Document: (tensor(21460), tensor(10624), tensor(17751), tensor(14488), tensor(10028), tensor(13883), tensor(20641), tensor(13090))\n",
            "\n",
            "Batch 26:\n",
            "Input IDs: torch.Size([8, 1438])\n",
            "Attention_mask: torch.Size([8, 1438])\n",
            "Labels: torch.Size([8, 1438, 13])\n",
            "Document: (tensor(20135), tensor(12675), tensor(12276), tensor(15430), tensor(21426), tensor(20562), tensor(9050), tensor(10301))\n",
            "\n",
            "Batch 27:\n",
            "Input IDs: torch.Size([8, 1154])\n",
            "Attention_mask: torch.Size([8, 1154])\n",
            "Labels: torch.Size([8, 1154, 13])\n",
            "Document: (tensor(22111), tensor(9726), tensor(18048), tensor(10730), tensor(10112), tensor(13941), tensor(22577), tensor(21003))\n",
            "\n",
            "Batch 28:\n",
            "Input IDs: torch.Size([8, 989])\n",
            "Attention_mask: torch.Size([8, 989])\n",
            "Labels: torch.Size([8, 989, 13])\n",
            "Document: (tensor(7408), tensor(21834), tensor(17234), tensor(10755), tensor(7770), tensor(1753), tensor(11753), tensor(21457))\n",
            "\n",
            "Batch 29:\n",
            "Input IDs: torch.Size([8, 1396])\n",
            "Attention_mask: torch.Size([8, 1396])\n",
            "Labels: torch.Size([8, 1396, 13])\n",
            "Document: (tensor(15751), tensor(16129), tensor(19171), tensor(16311), tensor(9106), tensor(9964), tensor(13288), tensor(20495))\n",
            "\n",
            "Batch 30:\n",
            "Input IDs: torch.Size([8, 1157])\n",
            "Attention_mask: torch.Size([8, 1157])\n",
            "Labels: torch.Size([8, 1157, 13])\n",
            "Document: (tensor(20198), tensor(19900), tensor(10668), tensor(12003), tensor(7708), tensor(15262), tensor(18536), tensor(18374))\n",
            "\n",
            "Batch 31:\n",
            "Input IDs: torch.Size([8, 1546])\n",
            "Attention_mask: torch.Size([8, 1546])\n",
            "Labels: torch.Size([8, 1546, 13])\n",
            "Document: (tensor(330), tensor(5935), tensor(14113), tensor(19481), tensor(17984), tensor(9314), tensor(17806), tensor(21217))\n",
            "\n",
            "Batch 32:\n",
            "Input IDs: torch.Size([8, 1733])\n",
            "Attention_mask: torch.Size([8, 1733])\n",
            "Labels: torch.Size([8, 1733, 13])\n",
            "Document: (tensor(9301), tensor(14071), tensor(18018), tensor(4765), tensor(12260), tensor(12998), tensor(11177), tensor(9021))\n",
            "\n",
            "Batch 33:\n",
            "Input IDs: torch.Size([8, 1357])\n",
            "Attention_mask: torch.Size([8, 1357])\n",
            "Labels: torch.Size([8, 1357, 13])\n",
            "Document: (tensor(18053), tensor(14599), tensor(16869), tensor(9943), tensor(19500), tensor(14403), tensor(5083), tensor(16467))\n",
            "\n",
            "Batch 34:\n",
            "Input IDs: torch.Size([8, 1265])\n",
            "Attention_mask: torch.Size([8, 1265])\n",
            "Labels: torch.Size([8, 1265, 13])\n",
            "Document: (tensor(15493), tensor(18922), tensor(15045), tensor(22227), tensor(13271), tensor(13437), tensor(21922), tensor(21966))\n",
            "\n",
            "Batch 35:\n",
            "Input IDs: torch.Size([8, 1596])\n",
            "Attention_mask: torch.Size([8, 1596])\n",
            "Labels: torch.Size([8, 1596, 13])\n",
            "Document: (tensor(17916), tensor(11412), tensor(12271), tensor(19722), tensor(9973), tensor(18643), tensor(12823), tensor(20672))\n",
            "\n",
            "Batch 36:\n",
            "Input IDs: torch.Size([8, 1272])\n",
            "Attention_mask: torch.Size([8, 1272])\n",
            "Labels: torch.Size([8, 1272, 13])\n",
            "Document: (tensor(12366), tensor(11389), tensor(11469), tensor(19206), tensor(14313), tensor(21669), tensor(651), tensor(16900))\n",
            "\n",
            "Batch 37:\n",
            "Input IDs: torch.Size([8, 1029])\n",
            "Attention_mask: torch.Size([8, 1029])\n",
            "Labels: torch.Size([8, 1029, 13])\n",
            "Document: (tensor(14193), tensor(21222), tensor(8076), tensor(16532), tensor(18507), tensor(21578), tensor(10798), tensor(22435))\n",
            "\n",
            "Batch 38:\n",
            "Input IDs: torch.Size([8, 1432])\n",
            "Attention_mask: torch.Size([8, 1432])\n",
            "Labels: torch.Size([8, 1432, 13])\n",
            "Document: (tensor(14926), tensor(317), tensor(2882), tensor(13815), tensor(9255), tensor(15719), tensor(12249), tensor(19952))\n",
            "\n",
            "Batch 39:\n",
            "Input IDs: torch.Size([8, 1126])\n",
            "Attention_mask: torch.Size([8, 1126])\n",
            "Labels: torch.Size([8, 1126, 13])\n",
            "Document: (tensor(16394), tensor(19235), tensor(10770), tensor(20006), tensor(20474), tensor(19929), tensor(21730), tensor(14817))\n",
            "\n",
            "Batch 40:\n",
            "Input IDs: torch.Size([8, 972])\n",
            "Attention_mask: torch.Size([8, 972])\n",
            "Labels: torch.Size([8, 972, 13])\n",
            "Document: (tensor(12481), tensor(19265), tensor(18377), tensor(2694), tensor(12649), tensor(17158), tensor(12437), tensor(17752))\n",
            "\n",
            "Batch 41:\n",
            "Input IDs: torch.Size([8, 1043])\n",
            "Attention_mask: torch.Size([8, 1043])\n",
            "Labels: torch.Size([8, 1043, 13])\n",
            "Document: (tensor(13854), tensor(12876), tensor(11590), tensor(9345), tensor(14393), tensor(16009), tensor(19429), tensor(14447))\n",
            "\n",
            "Batch 42:\n",
            "Input IDs: torch.Size([8, 1371])\n",
            "Attention_mask: torch.Size([8, 1371])\n",
            "Labels: torch.Size([8, 1371, 13])\n",
            "Document: (tensor(12294), tensor(9600), tensor(2813), tensor(19861), tensor(22288), tensor(7929), tensor(11854), tensor(22309))\n",
            "\n",
            "Batch 43:\n",
            "Input IDs: torch.Size([8, 1122])\n",
            "Attention_mask: torch.Size([8, 1122])\n",
            "Labels: torch.Size([8, 1122, 13])\n",
            "Document: (tensor(760), tensor(22477), tensor(21372), tensor(18757), tensor(9290), tensor(9157), tensor(14978), tensor(21819))\n",
            "\n",
            "Batch 44:\n",
            "Input IDs: torch.Size([8, 1392])\n",
            "Attention_mask: torch.Size([8, 1392])\n",
            "Labels: torch.Size([8, 1392, 13])\n",
            "Document: (tensor(9508), tensor(22313), tensor(9040), tensor(10485), tensor(21647), tensor(16224), tensor(14846), tensor(19435))\n",
            "\n",
            "Batch 45:\n",
            "Input IDs: torch.Size([8, 1144])\n",
            "Attention_mask: torch.Size([8, 1144])\n",
            "Labels: torch.Size([8, 1144, 13])\n",
            "Document: (tensor(10481), tensor(15459), tensor(5271), tensor(12757), tensor(11461), tensor(19797), tensor(14218), tensor(10600))\n",
            "\n",
            "Batch 46:\n",
            "Input IDs: torch.Size([8, 2145])\n",
            "Attention_mask: torch.Size([8, 2145])\n",
            "Labels: torch.Size([8, 2145, 13])\n",
            "Document: (tensor(21955), tensor(15300), tensor(6088), tensor(11901), tensor(14327), tensor(14604), tensor(14621), tensor(10845))\n",
            "\n",
            "Batch 47:\n",
            "Input IDs: torch.Size([8, 1823])\n",
            "Attention_mask: torch.Size([8, 1823])\n",
            "Labels: torch.Size([8, 1823, 13])\n",
            "Document: (tensor(375), tensor(9823), tensor(22150), tensor(15868), tensor(21349), tensor(13892), tensor(11102), tensor(22536))\n",
            "\n",
            "Batch 48:\n",
            "Input IDs: torch.Size([8, 1039])\n",
            "Attention_mask: torch.Size([8, 1039])\n",
            "Labels: torch.Size([8, 1039, 13])\n",
            "Document: (tensor(9086), tensor(9103), tensor(9864), tensor(22093), tensor(21318), tensor(15259), tensor(11123), tensor(13368))\n",
            "\n",
            "Batch 49:\n",
            "Input IDs: torch.Size([8, 899])\n",
            "Attention_mask: torch.Size([8, 899])\n",
            "Labels: torch.Size([8, 899, 13])\n",
            "Document: (tensor(19092), tensor(11339), tensor(17813), tensor(14855), tensor(15741), tensor(22216), tensor(8485), tensor(11952))\n",
            "\n",
            "Batch 50:\n",
            "Input IDs: torch.Size([8, 679])\n",
            "Attention_mask: torch.Size([8, 679])\n",
            "Labels: torch.Size([8, 679, 13])\n",
            "Document: (tensor(22415), tensor(15701), tensor(9571), tensor(14576), tensor(13503), tensor(14587), tensor(19768), tensor(13282))\n",
            "\n",
            "Batch 51:\n",
            "Input IDs: torch.Size([8, 2190])\n",
            "Attention_mask: torch.Size([8, 2190])\n",
            "Labels: torch.Size([8, 2190, 13])\n",
            "Document: (tensor(20651), tensor(11105), tensor(20274), tensor(19363), tensor(7256), tensor(6595), tensor(15533), tensor(20170))\n",
            "\n",
            "Batch 52:\n",
            "Input IDs: torch.Size([8, 1560])\n",
            "Attention_mask: torch.Size([8, 1560])\n",
            "Labels: torch.Size([8, 1560, 13])\n",
            "Document: (tensor(19820), tensor(4521), tensor(16105), tensor(4004), tensor(15831), tensor(8878), tensor(11557), tensor(15736))\n",
            "\n",
            "Batch 53:\n",
            "Input IDs: torch.Size([8, 1133])\n",
            "Attention_mask: torch.Size([8, 1133])\n",
            "Labels: torch.Size([8, 1133, 13])\n",
            "Document: (tensor(14850), tensor(22172), tensor(9251), tensor(10925), tensor(18480), tensor(7713), tensor(18679), tensor(18119))\n",
            "\n",
            "Batch 54:\n",
            "Input IDs: torch.Size([8, 1109])\n",
            "Attention_mask: torch.Size([8, 1109])\n",
            "Labels: torch.Size([8, 1109, 13])\n",
            "Document: (tensor(10324), tensor(15587), tensor(10997), tensor(14348), tensor(13178), tensor(12705), tensor(10440), tensor(12995))\n",
            "\n",
            "Batch 55:\n",
            "Input IDs: torch.Size([8, 1953])\n",
            "Attention_mask: torch.Size([8, 1953])\n",
            "Labels: torch.Size([8, 1953, 13])\n",
            "Document: (tensor(10067), tensor(14274), tensor(17753), tensor(19582), tensor(12738), tensor(10731), tensor(12369), tensor(21582))\n",
            "\n",
            "Batch 56:\n",
            "Input IDs: torch.Size([8, 1655])\n",
            "Attention_mask: torch.Size([8, 1655])\n",
            "Labels: torch.Size([8, 1655, 13])\n",
            "Document: (tensor(15340), tensor(15969), tensor(16127), tensor(19706), tensor(13166), tensor(15554), tensor(15851), tensor(20147))\n",
            "\n",
            "Batch 57:\n",
            "Input IDs: torch.Size([8, 1047])\n",
            "Attention_mask: torch.Size([8, 1047])\n",
            "Labels: torch.Size([8, 1047, 13])\n",
            "Document: (tensor(10735), tensor(15716), tensor(13681), tensor(12313), tensor(9141), tensor(12865), tensor(6941), tensor(22377))\n",
            "\n",
            "Batch 58:\n",
            "Input IDs: torch.Size([8, 1587])\n",
            "Attention_mask: torch.Size([8, 1587])\n",
            "Labels: torch.Size([8, 1587, 13])\n",
            "Document: (tensor(19414), tensor(10625), tensor(18822), tensor(19397), tensor(10472), tensor(17858), tensor(22456), tensor(14537))\n",
            "\n",
            "Batch 59:\n",
            "Input IDs: torch.Size([8, 1332])\n",
            "Attention_mask: torch.Size([8, 1332])\n",
            "Labels: torch.Size([8, 1332, 13])\n",
            "Document: (tensor(11916), tensor(2672), tensor(14013), tensor(22653), tensor(10752), tensor(12155), tensor(14200), tensor(14491))\n",
            "\n",
            "Batch 60:\n",
            "Input IDs: torch.Size([8, 1094])\n",
            "Attention_mask: torch.Size([8, 1094])\n",
            "Labels: torch.Size([8, 1094, 13])\n",
            "Document: (tensor(19403), tensor(7735), tensor(20984), tensor(12069), tensor(16529), tensor(10008), tensor(14512), tensor(21755))\n",
            "\n",
            "Batch 61:\n",
            "Input IDs: torch.Size([8, 1457])\n",
            "Attention_mask: torch.Size([8, 1457])\n",
            "Labels: torch.Size([8, 1457, 13])\n",
            "Document: (tensor(7993), tensor(10014), tensor(20588), tensor(20322), tensor(17171), tensor(13202), tensor(17260), tensor(14376))\n",
            "\n",
            "Batch 62:\n",
            "Input IDs: torch.Size([8, 1348])\n",
            "Attention_mask: torch.Size([8, 1348])\n",
            "Labels: torch.Size([8, 1348, 13])\n",
            "Document: (tensor(5952), tensor(12868), tensor(13667), tensor(15714), tensor(20078), tensor(20812), tensor(18328), tensor(6622))\n",
            "\n",
            "Batch 63:\n",
            "Input IDs: torch.Size([8, 1540])\n",
            "Attention_mask: torch.Size([8, 1540])\n",
            "Labels: torch.Size([8, 1540, 13])\n",
            "Document: (tensor(15842), tensor(19240), tensor(21682), tensor(19836), tensor(9639), tensor(5964), tensor(20304), tensor(11160))\n",
            "\n",
            "Batch 64:\n",
            "Input IDs: torch.Size([8, 1201])\n",
            "Attention_mask: torch.Size([8, 1201])\n",
            "Labels: torch.Size([8, 1201, 13])\n",
            "Document: (tensor(21413), tensor(21109), tensor(12216), tensor(21882), tensor(19853), tensor(22146), tensor(22302), tensor(14539))\n",
            "\n",
            "Batch 65:\n",
            "Input IDs: torch.Size([8, 1053])\n",
            "Attention_mask: torch.Size([8, 1053])\n",
            "Labels: torch.Size([8, 1053, 13])\n",
            "Document: (tensor(15997), tensor(10597), tensor(22357), tensor(18159), tensor(18136), tensor(12106), tensor(18095), tensor(2790))\n",
            "\n",
            "Batch 66:\n",
            "Input IDs: torch.Size([8, 979])\n",
            "Attention_mask: torch.Size([8, 979])\n",
            "Labels: torch.Size([8, 979, 13])\n",
            "Document: (tensor(9223), tensor(17650), tensor(19694), tensor(12950), tensor(20337), tensor(18277), tensor(4509), tensor(19511))\n",
            "\n",
            "Batch 67:\n",
            "Input IDs: torch.Size([8, 1464])\n",
            "Attention_mask: torch.Size([8, 1464])\n",
            "Labels: torch.Size([8, 1464, 13])\n",
            "Document: (tensor(12679), tensor(8805), tensor(2054), tensor(13075), tensor(9711), tensor(9636), tensor(10016), tensor(17277))\n",
            "\n",
            "Batch 68:\n",
            "Input IDs: torch.Size([8, 1755])\n",
            "Attention_mask: torch.Size([8, 1755])\n",
            "Labels: torch.Size([8, 1755, 13])\n",
            "Document: (tensor(20383), tensor(10151), tensor(14740), tensor(12750), tensor(12588), tensor(8733), tensor(10783), tensor(10409))\n",
            "\n",
            "Batch 69:\n",
            "Input IDs: torch.Size([8, 1589])\n",
            "Attention_mask: torch.Size([8, 1589])\n",
            "Labels: torch.Size([8, 1589, 13])\n",
            "Document: (tensor(9797), tensor(20989), tensor(19548), tensor(20656), tensor(17001), tensor(12870), tensor(20378), tensor(17245))\n",
            "\n",
            "Batch 70:\n",
            "Input IDs: torch.Size([8, 948])\n",
            "Attention_mask: torch.Size([8, 948])\n",
            "Labels: torch.Size([8, 948, 13])\n",
            "Document: (tensor(12490), tensor(11240), tensor(21698), tensor(4669), tensor(11161), tensor(12819), tensor(21471), tensor(22443))\n",
            "\n",
            "Batch 71:\n",
            "Input IDs: torch.Size([8, 1003])\n",
            "Attention_mask: torch.Size([8, 1003])\n",
            "Labels: torch.Size([8, 1003, 13])\n",
            "Document: (tensor(20060), tensor(21793), tensor(11819), tensor(15437), tensor(14992), tensor(14196), tensor(9685), tensor(10010))\n",
            "\n",
            "Batch 72:\n",
            "Input IDs: torch.Size([8, 945])\n",
            "Attention_mask: torch.Size([8, 945])\n",
            "Labels: torch.Size([8, 945, 13])\n",
            "Document: (tensor(16816), tensor(20878), tensor(12193), tensor(11409), tensor(14065), tensor(22228), tensor(10846), tensor(17925))\n",
            "\n",
            "Batch 73:\n",
            "Input IDs: torch.Size([8, 1027])\n",
            "Attention_mask: torch.Size([8, 1027])\n",
            "Labels: torch.Size([8, 1027, 13])\n",
            "Document: (tensor(14349), tensor(8867), tensor(17306), tensor(6859), tensor(19284), tensor(18556), tensor(1175), tensor(11128))\n",
            "\n",
            "Batch 74:\n",
            "Input IDs: torch.Size([8, 1200])\n",
            "Attention_mask: torch.Size([8, 1200])\n",
            "Labels: torch.Size([8, 1200, 13])\n",
            "Document: (tensor(12625), tensor(13847), tensor(11605), tensor(10490), tensor(17457), tensor(16501), tensor(19072), tensor(14446))\n",
            "\n",
            "Batch 75:\n",
            "Input IDs: torch.Size([8, 1265])\n",
            "Attention_mask: torch.Size([8, 1265])\n",
            "Labels: torch.Size([8, 1265, 13])\n",
            "Document: (tensor(15742), tensor(17711), tensor(13092), tensor(11838), tensor(20302), tensor(16511), tensor(10836), tensor(10606))\n",
            "\n",
            "Batch 76:\n",
            "Input IDs: torch.Size([8, 1461])\n",
            "Attention_mask: torch.Size([8, 1461])\n",
            "Labels: torch.Size([8, 1461, 13])\n",
            "Document: (tensor(10055), tensor(13121), tensor(17038), tensor(21093), tensor(15332), tensor(10314), tensor(8631), tensor(18442))\n",
            "\n",
            "Batch 77:\n",
            "Input IDs: torch.Size([8, 1438])\n",
            "Attention_mask: torch.Size([8, 1438])\n",
            "Labels: torch.Size([8, 1438, 13])\n",
            "Document: (tensor(21042), tensor(9095), tensor(5662), tensor(9657), tensor(9803), tensor(20852), tensor(18307), tensor(22055))\n",
            "\n",
            "Batch 78:\n",
            "Input IDs: torch.Size([8, 1251])\n",
            "Attention_mask: torch.Size([8, 1251])\n",
            "Labels: torch.Size([8, 1251, 13])\n",
            "Document: (tensor(22225), tensor(14443), tensor(10956), tensor(14675), tensor(8910), tensor(13251), tensor(19618), tensor(21990))\n",
            "\n",
            "Batch 79:\n",
            "Input IDs: torch.Size([8, 1013])\n",
            "Attention_mask: torch.Size([8, 1013])\n",
            "Labels: torch.Size([8, 1013, 13])\n",
            "Document: (tensor(14050), tensor(20414), tensor(20029), tensor(17549), tensor(6174), tensor(14957), tensor(10059), tensor(11982))\n",
            "\n",
            "Batch 80:\n",
            "Input IDs: torch.Size([8, 962])\n",
            "Attention_mask: torch.Size([8, 962])\n",
            "Labels: torch.Size([8, 962, 13])\n",
            "Document: (tensor(9324), tensor(9741), tensor(18452), tensor(2780), tensor(7676), tensor(20223), tensor(18385), tensor(10396))\n",
            "\n",
            "Batch 81:\n",
            "Input IDs: torch.Size([8, 1266])\n",
            "Attention_mask: torch.Size([8, 1266])\n",
            "Labels: torch.Size([8, 1266, 13])\n",
            "Document: (tensor(10538), tensor(11262), tensor(19003), tensor(4040), tensor(6257), tensor(8995), tensor(18209), tensor(9755))\n",
            "\n",
            "Batch 82:\n",
            "Input IDs: torch.Size([8, 944])\n",
            "Attention_mask: torch.Size([8, 944])\n",
            "Labels: torch.Size([8, 944, 13])\n",
            "Document: (tensor(12405), tensor(19813), tensor(12299), tensor(20468), tensor(18055), tensor(19943), tensor(22438), tensor(11729))\n",
            "\n",
            "Batch 83:\n",
            "Input IDs: torch.Size([8, 911])\n",
            "Attention_mask: torch.Size([8, 911])\n",
            "Labels: torch.Size([8, 911, 13])\n",
            "Document: (tensor(13924), tensor(15622), tensor(11529), tensor(8982), tensor(19730), tensor(13908), tensor(15580), tensor(20082))\n",
            "\n",
            "Batch 84:\n",
            "Input IDs: torch.Size([8, 1440])\n",
            "Attention_mask: torch.Size([8, 1440])\n",
            "Labels: torch.Size([8, 1440, 13])\n",
            "Document: (tensor(20097), tensor(18640), tensor(4185), tensor(10859), tensor(20041), tensor(12137), tensor(16967), tensor(10053))\n",
            "\n",
            "Batch 85:\n",
            "Input IDs: torch.Size([8, 1443])\n",
            "Attention_mask: torch.Size([8, 1443])\n",
            "Labels: torch.Size([8, 1443, 13])\n",
            "Document: (tensor(19112), tensor(21142), tensor(14500), tensor(11907), tensor(9872), tensor(12392), tensor(14613), tensor(10232))\n",
            "\n",
            "Batch 86:\n",
            "Input IDs: torch.Size([8, 1148])\n",
            "Attention_mask: torch.Size([8, 1148])\n",
            "Labels: torch.Size([8, 1148, 13])\n",
            "Document: (tensor(12603), tensor(11942), tensor(17415), tensor(14037), tensor(15148), tensor(13722), tensor(22297), tensor(16063))\n",
            "\n",
            "Batch 87:\n",
            "Input IDs: torch.Size([8, 1177])\n",
            "Attention_mask: torch.Size([8, 1177])\n",
            "Labels: torch.Size([8, 1177, 13])\n",
            "Document: (tensor(6531), tensor(18326), tensor(9664), tensor(5796), tensor(15753), tensor(9740), tensor(15445), tensor(20774))\n",
            "\n",
            "Batch 88:\n",
            "Input IDs: torch.Size([8, 1141])\n",
            "Attention_mask: torch.Size([8, 1141])\n",
            "Labels: torch.Size([8, 1141, 13])\n",
            "Document: (tensor(19921), tensor(11585), tensor(11250), tensor(19745), tensor(12187), tensor(21206), tensor(9652), tensor(11210))\n",
            "\n",
            "Batch 89:\n",
            "Input IDs: torch.Size([8, 1031])\n",
            "Attention_mask: torch.Size([8, 1031])\n",
            "Labels: torch.Size([8, 1031, 13])\n",
            "Document: (tensor(17456), tensor(21563), tensor(10648), tensor(9730), tensor(19692), tensor(9854), tensor(11611), tensor(20014))\n",
            "\n",
            "Batch 90:\n",
            "Input IDs: torch.Size([8, 916])\n",
            "Attention_mask: torch.Size([8, 916])\n",
            "Labels: torch.Size([8, 916, 13])\n",
            "Document: (tensor(5944), tensor(5085), tensor(18627), tensor(16769), tensor(20572), tensor(4913), tensor(21392), tensor(21824))\n",
            "\n",
            "Batch 91:\n",
            "Input IDs: torch.Size([8, 1028])\n",
            "Attention_mask: torch.Size([8, 1028])\n",
            "Labels: torch.Size([8, 1028, 13])\n",
            "Document: (tensor(17722), tensor(21090), tensor(19399), tensor(13906), tensor(2802), tensor(19170), tensor(5910), tensor(12759))\n",
            "\n",
            "Batch 92:\n",
            "Input IDs: torch.Size([8, 1070])\n",
            "Attention_mask: torch.Size([8, 1070])\n",
            "Labels: torch.Size([8, 1070, 13])\n",
            "Document: (tensor(22037), tensor(10457), tensor(15396), tensor(14819), tensor(9840), tensor(17644), tensor(12287), tensor(10431))\n",
            "\n",
            "Batch 93:\n",
            "Input IDs: torch.Size([8, 1433])\n",
            "Attention_mask: torch.Size([8, 1433])\n",
            "Labels: torch.Size([8, 1433, 13])\n",
            "Document: (tensor(13648), tensor(12670), tensor(13160), tensor(21052), tensor(10463), tensor(17976), tensor(14314), tensor(10255))\n",
            "\n",
            "Batch 94:\n",
            "Input IDs: torch.Size([8, 1230])\n",
            "Attention_mask: torch.Size([8, 1230])\n",
            "Labels: torch.Size([8, 1230, 13])\n",
            "Document: (tensor(13103), tensor(9989), tensor(15021), tensor(12662), tensor(15070), tensor(16973), tensor(19199), tensor(12502))\n",
            "\n",
            "Batch 95:\n",
            "Input IDs: torch.Size([8, 968])\n",
            "Attention_mask: torch.Size([8, 968])\n",
            "Labels: torch.Size([8, 968, 13])\n",
            "Document: (tensor(5296), tensor(15322), tensor(14133), tensor(10392), tensor(17201), tensor(20310), tensor(11591), tensor(17692))\n",
            "\n",
            "Batch 96:\n",
            "Input IDs: torch.Size([8, 1263])\n",
            "Attention_mask: torch.Size([8, 1263])\n",
            "Labels: torch.Size([8, 1263, 13])\n",
            "Document: (tensor(269), tensor(13376), tensor(16151), tensor(12981), tensor(112), tensor(21213), tensor(16208), tensor(6074))\n",
            "\n",
            "Batch 97:\n",
            "Input IDs: torch.Size([8, 1570])\n",
            "Attention_mask: torch.Size([8, 1570])\n",
            "Labels: torch.Size([8, 1570, 13])\n",
            "Document: (tensor(16396), tensor(10515), tensor(21124), tensor(17836), tensor(16044), tensor(14173), tensor(14316), tensor(6124))\n",
            "\n",
            "Batch 98:\n",
            "Input IDs: torch.Size([8, 1053])\n",
            "Attention_mask: torch.Size([8, 1053])\n",
            "Labels: torch.Size([8, 1053, 13])\n",
            "Document: (tensor(21529), tensor(18570), tensor(17683), tensor(12354), tensor(16679), tensor(20917), tensor(12288), tensor(8871))\n",
            "\n",
            "Batch 99:\n",
            "Input IDs: torch.Size([8, 958])\n",
            "Attention_mask: torch.Size([8, 958])\n",
            "Labels: torch.Size([8, 958, 13])\n",
            "Document: (tensor(11260), tensor(13591), tensor(22550), tensor(9795), tensor(13886), tensor(14900), tensor(21499), tensor(17647))\n",
            "\n",
            "Batch 100:\n",
            "Input IDs: torch.Size([8, 1338])\n",
            "Attention_mask: torch.Size([8, 1338])\n",
            "Labels: torch.Size([8, 1338, 13])\n",
            "Document: (tensor(21335), tensor(20902), tensor(20004), tensor(9551), tensor(12447), tensor(16688), tensor(11448), tensor(13831))\n",
            "\n",
            "Batch 101:\n",
            "Input IDs: torch.Size([8, 1191])\n",
            "Attention_mask: torch.Size([8, 1191])\n",
            "Labels: torch.Size([8, 1191, 13])\n",
            "Document: (tensor(4486), tensor(22125), tensor(10467), tensor(15362), tensor(16012), tensor(12512), tensor(15724), tensor(7222))\n",
            "\n",
            "Batch 102:\n",
            "Input IDs: torch.Size([8, 1152])\n",
            "Attention_mask: torch.Size([8, 1152])\n",
            "Labels: torch.Size([8, 1152, 13])\n",
            "Document: (tensor(16828), tensor(20421), tensor(22273), tensor(21488), tensor(19631), tensor(18619), tensor(10720), tensor(10458))\n",
            "\n",
            "Batch 103:\n",
            "Input IDs: torch.Size([8, 1329])\n",
            "Attention_mask: torch.Size([8, 1329])\n",
            "Labels: torch.Size([8, 1329, 13])\n",
            "Document: (tensor(17140), tensor(2732), tensor(10656), tensor(10495), tensor(13878), tensor(7115), tensor(21699), tensor(13825))\n",
            "\n",
            "Batch 104:\n",
            "Input IDs: torch.Size([8, 724])\n",
            "Attention_mask: torch.Size([8, 724])\n",
            "Labels: torch.Size([8, 724, 13])\n",
            "Document: (tensor(18085), tensor(18885), tensor(20496), tensor(8833), tensor(16528), tensor(21783), tensor(13769), tensor(17191))\n",
            "\n",
            "Batch 105:\n",
            "Input IDs: torch.Size([8, 1449])\n",
            "Attention_mask: torch.Size([8, 1449])\n",
            "Labels: torch.Size([8, 1449, 13])\n",
            "Document: (tensor(19086), tensor(17113), tensor(13628), tensor(17599), tensor(4381), tensor(19101), tensor(18781), tensor(10317))\n",
            "\n",
            "Batch 106:\n",
            "Input IDs: torch.Size([8, 847])\n",
            "Attention_mask: torch.Size([8, 847])\n",
            "Labels: torch.Size([8, 847, 13])\n",
            "Document: (tensor(14310), tensor(14505), tensor(17847), tensor(21149), tensor(20842), tensor(19505), tensor(7865), tensor(16263))\n",
            "\n",
            "Batch 107:\n",
            "Input IDs: torch.Size([8, 1334])\n",
            "Attention_mask: torch.Size([8, 1334])\n",
            "Labels: torch.Size([8, 1334, 13])\n",
            "Document: (tensor(17098), tensor(10946), tensor(21538), tensor(14840), tensor(20589), tensor(12057), tensor(15641), tensor(21763))\n",
            "\n",
            "Batch 108:\n",
            "Input IDs: torch.Size([8, 1177])\n",
            "Attention_mask: torch.Size([8, 1177])\n",
            "Labels: torch.Size([8, 1177, 13])\n",
            "Document: (tensor(19547), tensor(10561), tensor(9582), tensor(10114), tensor(21742), tensor(11714), tensor(11430), tensor(13342))\n",
            "\n",
            "Batch 109:\n",
            "Input IDs: torch.Size([8, 979])\n",
            "Attention_mask: torch.Size([8, 979])\n",
            "Labels: torch.Size([8, 979, 13])\n",
            "Document: (tensor(4868), tensor(22206), tensor(10721), tensor(11933), tensor(13532), tensor(16487), tensor(11399), tensor(14966))\n",
            "\n",
            "Batch 110:\n",
            "Input IDs: torch.Size([8, 1011])\n",
            "Attention_mask: torch.Size([8, 1011])\n",
            "Labels: torch.Size([8, 1011, 13])\n",
            "Document: (tensor(10588), tensor(16556), tensor(16821), tensor(19725), tensor(10651), tensor(18949), tensor(13627), tensor(19804))\n",
            "\n",
            "Batch 111:\n",
            "Input IDs: torch.Size([8, 1050])\n",
            "Attention_mask: torch.Size([8, 1050])\n",
            "Labels: torch.Size([8, 1050, 13])\n",
            "Document: (tensor(10761), tensor(10401), tensor(9758), tensor(18682), tensor(13153), tensor(19344), tensor(15791), tensor(19625))\n",
            "\n",
            "Batch 112:\n",
            "Input IDs: torch.Size([8, 780])\n",
            "Attention_mask: torch.Size([8, 780])\n",
            "Labels: torch.Size([8, 780, 13])\n",
            "Document: (tensor(5209), tensor(14713), tensor(10400), tensor(15855), tensor(13551), tensor(4799), tensor(20031), tensor(16161))\n",
            "\n",
            "Batch 113:\n",
            "Input IDs: torch.Size([8, 1092])\n",
            "Attention_mask: torch.Size([8, 1092])\n",
            "Labels: torch.Size([8, 1092, 13])\n",
            "Document: (tensor(1790), tensor(20569), tensor(10030), tensor(10902), tensor(18600), tensor(9724), tensor(21923), tensor(11705))\n",
            "\n",
            "Batch 114:\n",
            "Input IDs: torch.Size([8, 1555])\n",
            "Attention_mask: torch.Size([8, 1555])\n",
            "Labels: torch.Size([8, 1555, 13])\n",
            "Document: (tensor(22677), tensor(15915), tensor(12326), tensor(21418), tensor(13649), tensor(15162), tensor(10106), tensor(13556))\n",
            "\n",
            "Batch 115:\n",
            "Input IDs: torch.Size([8, 1351])\n",
            "Attention_mask: torch.Size([8, 1351])\n",
            "Labels: torch.Size([8, 1351, 13])\n",
            "Document: (tensor(20987), tensor(15740), tensor(19659), tensor(14625), tensor(9829), tensor(21891), tensor(14010), tensor(6577))\n",
            "\n",
            "Batch 116:\n",
            "Input IDs: torch.Size([8, 1275])\n",
            "Attention_mask: torch.Size([8, 1275])\n",
            "Labels: torch.Size([8, 1275, 13])\n",
            "Document: (tensor(21269), tensor(8584), tensor(21612), tensor(13800), tensor(19241), tensor(9140), tensor(5621), tensor(13136))\n",
            "\n",
            "Batch 117:\n",
            "Input IDs: torch.Size([8, 1359])\n",
            "Attention_mask: torch.Size([8, 1359])\n",
            "Labels: torch.Size([8, 1359, 13])\n",
            "Document: (tensor(9158), tensor(20561), tensor(18353), tensor(4413), tensor(19615), tensor(4295), tensor(21740), tensor(12304))\n",
            "\n",
            "Batch 118:\n",
            "Input IDs: torch.Size([8, 1519])\n",
            "Attention_mask: torch.Size([8, 1519])\n",
            "Labels: torch.Size([8, 1519, 13])\n",
            "Document: (tensor(10865), tensor(16773), tensor(16320), tensor(8033), tensor(18901), tensor(12186), tensor(14191), tensor(13754))\n",
            "\n",
            "Batch 119:\n",
            "Input IDs: torch.Size([8, 1743])\n",
            "Attention_mask: torch.Size([8, 1743])\n",
            "Labels: torch.Size([8, 1743, 13])\n",
            "Document: (tensor(13482), tensor(21224), tensor(9115), tensor(21554), tensor(8976), tensor(15543), tensor(13046), tensor(20180))\n",
            "\n",
            "Batch 120:\n",
            "Input IDs: torch.Size([8, 1244])\n",
            "Attention_mask: torch.Size([8, 1244])\n",
            "Labels: torch.Size([8, 1244, 13])\n",
            "Document: (tensor(12748), tensor(12858), tensor(19418), tensor(13414), tensor(16678), tensor(19482), tensor(4191), tensor(17067))\n",
            "\n",
            "Batch 121:\n",
            "Input IDs: torch.Size([8, 2073])\n",
            "Attention_mask: torch.Size([8, 2073])\n",
            "Labels: torch.Size([8, 2073, 13])\n",
            "Document: (tensor(22153), tensor(10404), tensor(8316), tensor(18501), tensor(12541), tensor(11474), tensor(5922), tensor(11670))\n",
            "\n",
            "Batch 122:\n",
            "Input IDs: torch.Size([8, 1030])\n",
            "Attention_mask: torch.Size([8, 1030])\n",
            "Labels: torch.Size([8, 1030, 13])\n",
            "Document: (tensor(20387), tensor(17531), tensor(5067), tensor(22210), tensor(15806), tensor(10064), tensor(8123), tensor(17940))\n",
            "\n",
            "Batch 123:\n",
            "Input IDs: torch.Size([8, 925])\n",
            "Attention_mask: torch.Size([8, 925])\n",
            "Labels: torch.Size([8, 925, 13])\n",
            "Document: (tensor(19386), tensor(17768), tensor(4750), tensor(19109), tensor(17231), tensor(19514), tensor(20188), tensor(11352))\n",
            "\n",
            "Batch 124:\n",
            "Input IDs: torch.Size([8, 1663])\n",
            "Attention_mask: torch.Size([8, 1663])\n",
            "Labels: torch.Size([8, 1663, 13])\n",
            "Document: (tensor(15938), tensor(18496), tensor(17842), tensor(21236), tensor(11213), tensor(10359), tensor(19310), tensor(14436))\n",
            "\n",
            "Batch 125:\n",
            "Input IDs: torch.Size([8, 1492])\n",
            "Attention_mask: torch.Size([8, 1492])\n",
            "Labels: torch.Size([8, 1492, 13])\n",
            "Document: (tensor(6085), tensor(16425), tensor(13643), tensor(15212), tensor(22672), tensor(14581), tensor(14955), tensor(19287))\n",
            "\n",
            "Batch 126:\n",
            "Input IDs: torch.Size([8, 1042])\n",
            "Attention_mask: torch.Size([8, 1042])\n",
            "Labels: torch.Size([8, 1042, 13])\n",
            "Document: (tensor(21723), tensor(12943), tensor(14185), tensor(9113), tensor(15707), tensor(17710), tensor(13116), tensor(10526))\n",
            "\n",
            "Batch 127:\n",
            "Input IDs: torch.Size([8, 1332])\n",
            "Attention_mask: torch.Size([8, 1332])\n",
            "Labels: torch.Size([8, 1332, 13])\n",
            "Document: (tensor(12883), tensor(16077), tensor(7265), tensor(6187), tensor(14068), tensor(14337), tensor(10659), tensor(14984))\n",
            "\n",
            "Batch 128:\n",
            "Input IDs: torch.Size([6, 1050])\n",
            "Attention_mask: torch.Size([6, 1050])\n",
            "Labels: torch.Size([6, 1050, 13])\n",
            "Document: (tensor(12295), tensor(16143), tensor(21153), tensor(5236), tensor(15782), tensor(17745))\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8iohHD7P0lJ"
      },
      "outputs": [],
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-3GgKnWP0lJ"
      },
      "outputs": [],
      "source": [
        "def val(model, custom_val, batch_size, custom_collate, criterion, device):\n",
        "    model.eval()\n",
        "\n",
        "    avg_val_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        val_loss = 0\n",
        "        val_score = {'f5': 0, 'recall': 0, 'precision': 0}\n",
        "        val_dataloader = DataLoader(custom_val, batch_size = batch_size, collate_fn = custom_collate, shuffle = False)\n",
        "\n",
        "        for batch, (input_ids, attention_mask, labels, doc) in enumerate(val_dataloader):\n",
        "\n",
        "            input_ids = input_ids.to(device)\n",
        "            attention_mask = attention_mask.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask).logits\n",
        "            loss = criterion(outputs, labels)\n",
        "            results = compute_metrics(outputs, labels)\n",
        "\n",
        "            val_loss += loss\n",
        "            val_score['f5'] += results['f5']\n",
        "            val_score['recall'] += results['recall']\n",
        "            val_score['precision'] += results['precision']\n",
        "\n",
        "            if batch%200 == 0 or batch+1 == len(val_dataloader):\n",
        "                print(\"********** For Validation Set **********\")\n",
        "                print(f\"Completed {batch+1}/{len(val_dataloader)}, with current val_loss: {loss: .4e},\\n current results:{results}\")\n",
        "\n",
        "    avg_val_loss = val_loss / len(custom_val)\n",
        "    for k in val_score:\n",
        "        val_score[k] /= len(val_dataloader)\n",
        "    # avg_val_score = val_score/len(val_dataloader)\n",
        "\n",
        "    print(f\"Average val_loss: {avg_val_loss: .4e}, avgerage val_score = {val_score}\")\n",
        "\n",
        "    return avg_val_loss, val_score['f5']    #Return only f5\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yo5SymfvP0lJ"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "def train(model, custom_train, custom_val, batch_size, custom_collate, epochs, optimizer, criterion,  device):\n",
        "\n",
        "    model.train()\n",
        "    best_val_loss = float('inf')\n",
        "    best_val_score = -float('inf')\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        start_time = time.time()\n",
        "        avg_train_loss = 0\n",
        "        train_loss = 0\n",
        "        train_score = {'f5': 0, 'recall': 0, 'precision': 0}\n",
        "\n",
        "\n",
        "        train_dataloader = DataLoader(custom_train, batch_size = batch_size, collate_fn = custom_collate, shuffle = True)\n",
        "        print('Starting training...')\n",
        "\n",
        "        for batch, (input_ids, attention_mask, labels, doc) in enumerate(train_dataloader):\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            input_ids = input_ids.to(device)\n",
        "            attention_mask = attention_mask.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask).logits\n",
        "            # print(outputs.size())\n",
        "            # print(labels.size())\n",
        "            # print(outputs)\n",
        "\n",
        "            loss = criterion(outputs, labels)\n",
        "            # print(f\"Loss: {loss:.4e}\")\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "\n",
        "            results = compute_metrics(outputs, labels)\n",
        "            train_loss += loss\n",
        "            train_score['f5']+= results['f5']\n",
        "            train_score['recall'] += results['recall']\n",
        "            train_score['precision'] += results['precision']\n",
        "\n",
        "\n",
        "\n",
        "            if batch%200 == 0 or batch+1 == len(train_dataloader):\n",
        "                results = compute_metrics(outputs, labels)\n",
        "                print(f\"Completed {batch+1}/{len(train_dataloader)}, with current train_loss: {loss: .4e},\\n current results:{results}\")\n",
        "\n",
        "        avg_train_loss = train_loss / len(custom_train)\n",
        "        for k in train_score:\n",
        "            train_score[k] /= len(train_dataloader)\n",
        "        #avg_train_score = train_score / len(train_dataloader)\n",
        "\n",
        "\n",
        "        end_time = time.time()\n",
        "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "        print()\n",
        "        print(f\"Epoch {epoch+1}/{epochs}: Average train_loss = {avg_train_loss: .4e}, average train_score = {train_score}\")\n",
        "\n",
        "        print()\n",
        "        print(\"Starting to validate\")\n",
        "        val_loss, val_score = val(model, custom_val, batch_size, custom_collate, criterion, device)\n",
        "\n",
        "        print(f\"Epoch time: {epoch_mins}m {epoch_secs}s\")\n",
        "        print()\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), 'T5_small_LoRA_best_loss.pt')\n",
        "\n",
        "        if val_score > best_val_score:\n",
        "            best_val_score = val_score\n",
        "            torch.save(model.state_dict(), 'T5_small_LoRA_best_score.pt')\n",
        "\n",
        "\n",
        "    torch.save(model.state_dict(), f'T5_small_LoRA_{epochs}.pt')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4e3oZGBP0lK"
      },
      "source": [
        "Running the function below will output the loss and results every 200 batches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8ZeronQP0lK",
        "outputId": "ea1a3ac5-f29f-4c65-ca87-19c39aa7e829",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training...\n",
            "Completed 1/724, with current train_loss:  9.1803e-04,\n",
            " current results:{'f5': 0.7878787878787878, 'recall': 1.0, 'precision': 0.125}\n",
            "Completed 201/724, with current train_loss:  1.2027e-03,\n",
            " current results:{'f5': 0.7546174142480211, 'recall': 1.0, 'precision': 0.10576923076923078}\n",
            "Completed 401/724, with current train_loss:  1.0971e-03,\n",
            " current results:{'f5': 0.7344632768361582, 'recall': 1.0, 'precision': 0.09615384615384616}\n",
            "Completed 601/724, with current train_loss:  1.1275e-03,\n",
            " current results:{'f5': 0.6842105263157894, 'recall': 1.0, 'precision': 0.07692307692307693}\n",
            "Completed 724/724, with current train_loss:  1.0340e-03,\n",
            " current results:{'f5': 0.6842105263157894, 'recall': 1.0, 'precision': 0.07692307692307693}\n",
            "\n",
            "Epoch 1/5: Average train_loss =  1.4279e-04, average train_score = {'f5': 0.7318610197008035, 'recall': 0.9997410220994475, 'precision': 0.09739893221419511}\n",
            "\n",
            "Starting to validate\n",
            "********** For Validation Set **********\n",
            "Completed 1/128, with current val_loss:  1.0839e-03,\n",
            " current results:{'f5': 0.7722772277227723, 'recall': 1.0, 'precision': 0.11538461538461539}\n",
            "********** For Validation Set **********\n",
            "Completed 128/128, with current val_loss:  1.0194e-03,\n",
            " current results:{'f5': 0.7926829268292683, 'recall': 1.0, 'precision': 0.1282051282051282}\n",
            "Average val_loss:  1.0968e-04, avgerage val_score = {'f5': 0.7375364196487542, 'recall': 0.9994303385416666, 'precision': 0.1002740748834498}\n",
            "Epoch time: 14m 6s\n",
            "\n",
            "Starting training...\n",
            "Completed 1/724, with current train_loss:  9.1620e-04,\n",
            " current results:{'f5': 0.7112462006079028, 'recall': 1.0, 'precision': 0.08653846153846154}\n",
            "Completed 201/724, with current train_loss:  9.6857e-04,\n",
            " current results:{'f5': 0.7344632768361582, 'recall': 1.0, 'precision': 0.09615384615384616}\n",
            "Completed 401/724, with current train_loss:  9.7847e-04,\n",
            " current results:{'f5': 0.7722772277227723, 'recall': 1.0, 'precision': 0.11538461538461539}\n",
            "Completed 601/724, with current train_loss:  5.3128e-04,\n",
            " current results:{'f5': 0.7344632768361582, 'recall': 1.0, 'precision': 0.09615384615384616}\n",
            "Completed 724/724, with current train_loss:  8.5382e-04,\n",
            " current results:{'f5': 0.6842105263157894, 'recall': 1.0, 'precision': 0.07692307692307693}\n",
            "\n",
            "Epoch 2/5: Average train_loss =  9.6123e-05, average train_score = {'f5': 0.731340435232545, 'recall': 0.9994331261510131, 'precision': 0.09735617168282952}\n",
            "\n",
            "Starting to validate\n",
            "********** For Validation Set **********\n",
            "Completed 1/128, with current val_loss:  7.7008e-04,\n",
            " current results:{'f5': 0.7722772277227723, 'recall': 1.0, 'precision': 0.11538461538461539}\n",
            "********** For Validation Set **********\n",
            "Completed 128/128, with current val_loss:  7.2585e-04,\n",
            " current results:{'f5': 0.7926829268292683, 'recall': 1.0, 'precision': 0.1282051282051282}\n",
            "Average val_loss:  7.8121e-05, avgerage val_score = {'f5': 0.737816919961648, 'recall': 0.9996744791666666, 'precision': 0.10034805689102559}\n",
            "Epoch time: 14m 7s\n",
            "\n",
            "Starting training...\n",
            "Completed 1/724, with current train_loss:  7.5989e-04,\n",
            " current results:{'f5': 0.756177563962388, 'recall': 1.0, 'precision': 0.10657051282051283}\n",
            "Completed 201/724, with current train_loss:  5.0798e-04,\n",
            " current results:{'f5': 0.7344632768361582, 'recall': 1.0, 'precision': 0.09615384615384616}\n",
            "Completed 401/724, with current train_loss:  5.1153e-04,\n",
            " current results:{'f5': 0.7546174142480211, 'recall': 1.0, 'precision': 0.10576923076923078}\n",
            "Completed 601/724, with current train_loss:  5.1057e-04,\n",
            " current results:{'f5': 0.7344632768361582, 'recall': 1.0, 'precision': 0.09615384615384616}\n",
            "Completed 724/724, with current train_loss:  9.4084e-04,\n",
            " current results:{'f5': 0.6842105263157894, 'recall': 1.0, 'precision': 0.07692307692307693}\n",
            "\n",
            "Epoch 3/5: Average train_loss =  6.8085e-05, average train_score = {'f5': 0.7320657829264302, 'recall': 0.9995913904235729, 'precision': 0.09740265489574915}\n",
            "\n",
            "Starting to validate\n",
            "********** For Validation Set **********\n",
            "Completed 1/128, with current val_loss:  5.3669e-04,\n",
            " current results:{'f5': 0.7722772277227723, 'recall': 1.0, 'precision': 0.11538461538461539}\n",
            "********** For Validation Set **********\n",
            "Completed 128/128, with current val_loss:  5.0741e-04,\n",
            " current results:{'f5': 0.7926829268292683, 'recall': 1.0, 'precision': 0.1282051282051282}\n",
            "Average val_loss:  5.4660e-05, avgerage val_score = {'f5': 0.7378222657461205, 'recall': 0.9996744791666666, 'precision': 0.10035545509178316}\n",
            "Epoch time: 14m 2s\n",
            "\n",
            "Starting training...\n",
            "Completed 1/724, with current train_loss:  5.0276e-04,\n",
            " current results:{'f5': 0.7546174142480211, 'recall': 1.0, 'precision': 0.10576923076923078}\n",
            "Completed 201/724, with current train_loss:  4.9654e-04,\n",
            " current results:{'f5': 0.7344632768361582, 'recall': 1.0, 'precision': 0.09615384615384616}\n",
            "Completed 401/724, with current train_loss:  4.6723e-04,\n",
            " current results:{'f5': 0.6842105263157894, 'recall': 1.0, 'precision': 0.07692307692307693}\n",
            "Completed 601/724, with current train_loss:  3.0091e-04,\n",
            " current results:{'f5': 0.7112462006079028, 'recall': 1.0, 'precision': 0.08653846153846154}\n",
            "Completed 724/724, with current train_loss:  1.2597e-03,\n",
            " current results:{'f5': 0.6842105263157894, 'recall': 1.0, 'precision': 0.07692307692307693}\n",
            "\n",
            "Epoch 4/5: Average train_loss =  4.7618e-05, average train_score = {'f5': 0.7315347056766629, 'recall': 0.9995338397790056, 'precision': 0.097407786159513}\n",
            "\n",
            "Starting to validate\n",
            "********** For Validation Set **********\n",
            "Completed 1/128, with current val_loss:  3.7409e-04,\n",
            " current results:{'f5': 0.7722772277227723, 'recall': 1.0, 'precision': 0.11538461538461539}\n",
            "********** For Validation Set **********\n",
            "Completed 128/128, with current val_loss:  3.5519e-04,\n",
            " current results:{'f5': 0.7926829268292683, 'recall': 1.0, 'precision': 0.1282051282051282}\n",
            "Average val_loss:  3.8298e-05, avgerage val_score = {'f5': 0.7381679240991452, 'recall': 1.0, 'precision': 0.10044309531614212}\n",
            "Epoch time: 14m 6s\n",
            "\n",
            "Starting training...\n",
            "Completed 1/724, with current train_loss:  2.7024e-04,\n",
            " current results:{'f5': 0.7878787878787878, 'recall': 1.0, 'precision': 0.125}\n",
            "Completed 201/724, with current train_loss:  3.7684e-04,\n",
            " current results:{'f5': 0.7344632768361582, 'recall': 1.0, 'precision': 0.09615384615384616}\n",
            "Completed 401/724, with current train_loss:  3.2350e-04,\n",
            " current results:{'f5': 0.7112462006079028, 'recall': 1.0, 'precision': 0.08653846153846154}\n",
            "Completed 601/724, with current train_loss:  2.2829e-04,\n",
            " current results:{'f5': 0.7344632768361582, 'recall': 1.0, 'precision': 0.09615384615384616}\n",
            "Completed 724/724, with current train_loss:  3.4601e-04,\n",
            " current results:{'f5': 0.6842105263157894, 'recall': 1.0, 'precision': 0.07692307692307693}\n",
            "\n",
            "Epoch 5/5: Average train_loss =  3.3751e-05, average train_score = {'f5': 0.7321659724796435, 'recall': 0.9997410220994475, 'precision': 0.09748938331465992}\n",
            "\n",
            "Starting to validate\n",
            "********** For Validation Set **********\n",
            "Completed 1/128, with current val_loss:  2.7048e-04,\n",
            " current results:{'f5': 0.7722772277227723, 'recall': 1.0, 'precision': 0.11538461538461539}\n",
            "********** For Validation Set **********\n",
            "Completed 128/128, with current val_loss:  2.5803e-04,\n",
            " current results:{'f5': 0.7926829268292683, 'recall': 1.0, 'precision': 0.1282051282051282}\n",
            "Average val_loss:  2.7839e-05, avgerage val_score = {'f5': 0.7382371621568635, 'recall': 1.0, 'precision': 0.10048065541229596}\n",
            "Epoch time: 13m 52s\n",
            "\n"
          ]
        }
      ],
      "source": [
        "batch_size = 8\n",
        "epochs = 5\n",
        "criterion = FocalLoss()\n",
        "\n",
        "train(model, custom_train, custom_val, batch_size, custom_collate, epochs, optimizer, criterion, device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, 'T5LoRAmodel_full.pth')"
      ],
      "metadata": {
        "id": "oX_FQkNBhLwY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('T5LoRAmodel_full.pth')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "kE77eyX7HdCA",
        "outputId": "986bee1d-56ac-43a9-92dc-3cbef74fc24b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b0ccdbdb-e641-46f3-8161-1119b6ec3db1\", \"T5LoRAmodel_full.pth\", 144582280)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files.download('T5_small_LoRA_5.pt')\n",
        "files.download('T5_small_LoRA_best_loss.pt')\n",
        "files.download('T5_small_LoRA_best_score.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "fUX0wbd9Hr2-",
        "outputId": "c902e4a9-eba0-4f7f-8352-4bba5ed7c28d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_888ce3fd-21b2-4763-a25a-26abcaec961c\", \"T5_small_LoRA_5.pt\", 144546743)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3007ac78-940a-42e0-bfe8-a512725ea743\", \"T5_small_LoRA_best_loss.pt\", 144547583)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_57b0b477-ebf5-4cce-8ee0-73ad74832dbe\", \"T5_small_LoRA_best_score.pt\", 144547664)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sZ6pYKHP0lK"
      },
      "source": [
        "# Converting from predictions to NER labels"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load model for testing\n",
        "#model = torch.load('T5model_full.pth')\n",
        "#model.eval()  # Set the model to evaluation mode"
      ],
      "metadata": {
        "id": "FXvzx6qnitTa"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f2206b9a9fe641b9a723f30b07a1e435": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_08839243a92f4a55a9c79573c54e34e9",
              "IPY_MODEL_7f850617a1244e8c847599cfe3d9864d",
              "IPY_MODEL_bbd2e8350d8a432da85cf9d1a2c183dd"
            ],
            "layout": "IPY_MODEL_d43e2ac16a734dda8a0e918c463c1ad2"
          }
        },
        "08839243a92f4a55a9c79573c54e34e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aec0dd539324488ab0bda7e20fb5e4ee",
            "placeholder": "",
            "style": "IPY_MODEL_6c5a6c4de11a4cdca36b842148ff1f60",
            "value": "Map(num_proc=3):100%"
          }
        },
        "7f850617a1244e8c847599cfe3d9864d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c80fbe0e7ccc49cca7545def9ae6d0f9",
            "max": 5785,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5c23a733d360454087c8b51862ef2573",
            "value": 5785
          }
        },
        "bbd2e8350d8a432da85cf9d1a2c183dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_934d8a50afe94ec5aa281a71a0dd835f",
            "placeholder": "",
            "style": "IPY_MODEL_baa2afc3a2724969b0b170403e0f96d0",
            "value": "5785/5785[00:15&lt;00:00,71.60examples/s]"
          }
        },
        "d43e2ac16a734dda8a0e918c463c1ad2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aec0dd539324488ab0bda7e20fb5e4ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c5a6c4de11a4cdca36b842148ff1f60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c80fbe0e7ccc49cca7545def9ae6d0f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c23a733d360454087c8b51862ef2573": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "934d8a50afe94ec5aa281a71a0dd835f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "baa2afc3a2724969b0b170403e0f96d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b75520d32464159aaf1df18a5d79557": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2845269df4af4d969f55ff24fcb22d6c",
              "IPY_MODEL_633cf20038dd4c2a83c54f3bc83c076b",
              "IPY_MODEL_b3550a6e502e4a879d976b058aee08f4"
            ],
            "layout": "IPY_MODEL_a5949a52513341a8bcefec74813a0975"
          }
        },
        "2845269df4af4d969f55ff24fcb22d6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a140a9d5f8494b74aae44b6559a35612",
            "placeholder": "",
            "style": "IPY_MODEL_ef189afc4e064787a1ad4f503dc66f77",
            "value": "Map(num_proc=3):100%"
          }
        },
        "633cf20038dd4c2a83c54f3bc83c076b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3992ca9a85849ea9b807e6d2f36120a",
            "max": 1022,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_658044d033914f9f8899b08733afd0a7",
            "value": 1022
          }
        },
        "b3550a6e502e4a879d976b058aee08f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7ed24318c5d44adb938faf7353c47a6",
            "placeholder": "",
            "style": "IPY_MODEL_07234c7b51544c27a05ecffa91cddfbb",
            "value": "1022/1022[00:03&lt;00:00,515.79examples/s]"
          }
        },
        "a5949a52513341a8bcefec74813a0975": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a140a9d5f8494b74aae44b6559a35612": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef189afc4e064787a1ad4f503dc66f77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c3992ca9a85849ea9b807e6d2f36120a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "658044d033914f9f8899b08733afd0a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c7ed24318c5d44adb938faf7353c47a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07234c7b51544c27a05ecffa91cddfbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}